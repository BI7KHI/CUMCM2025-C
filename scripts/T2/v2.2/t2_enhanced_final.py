#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
T2 v2.2ï¼šå¢å¼ºç‰ˆæœ€ç»ˆæ–¹æ¡ˆ
ä¿®å¤åˆ†ç»„é‡å é—®é¢˜ï¼Œå¢å¼ºé£é™©å‡½æ•°ï¼Œæä¾›æ›´ç²¾ç¡®çš„ä¸´åºŠæŒ‡å¯¼

ä¸»è¦æ”¹è¿›ï¼š
1. éé‡å åˆ†ç»„ç®—æ³•
2. å¢å¼ºçš„å¤šç»´é£é™©å‡½æ•°
3. ä¸ªæ€§åŒ–NIPTæ—¶ç‚¹é¢„æµ‹
4. æ”¹è¿›çš„äº¤å‰éªŒè¯æ¡†æ¶
5. è¯¦ç»†çš„ä¸´åºŠå†³ç­–æ”¯æŒ
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from scipy.optimize import minimize_scalar
from sklearn.cluster import KMeans
from sklearn.mixture import GaussianMixture
from sklearn.metrics import silhouette_score, adjusted_rand_score
from sklearn.model_selection import StratifiedKFold
from sklearn.ensemble import RandomForestRegressor
from lifelines import KaplanMeierFitter, CoxPHFitter
import os
import random
import matplotlib.font_manager as fm
import warnings
warnings.filterwarnings('ignore')

# å­—ä½“é…ç½®
def configure_chinese_font():
    try:
        candidate_families = [
            'WenQuanYi Zen Hei', 'Microsoft YaHei', 'SimHei', 'DejaVu Sans'
        ]
        
        installed = set(f.name for f in fm.fontManager.ttflist)
        for family in candidate_families:
            if family in installed:
                plt.rcParams['font.family'] = ['sans-serif']
                plt.rcParams['font.sans-serif'] = [family, 'DejaVu Sans']
                return family
        
        plt.rcParams['font.family'] = ['sans-serif'] 
        plt.rcParams['font.sans-serif'] = ['DejaVu Sans']
        return None
    except Exception:
        return None

family = configure_chinese_font()
if family:
    print(f"âœ… æˆåŠŸé…ç½®ä¸­æ–‡å­—ä½“: {family}")
else:
    print("âš ï¸ ä½¿ç”¨é»˜è®¤å­—ä½“ DejaVu Sans")

plt.rcParams['axes.unicode_minus'] = False

# é¡¹ç›®è·¯å¾„è®¾ç½®
script_dir = os.path.dirname(os.path.abspath(__file__))
project_root = os.path.dirname(script_dir)
results_dir = os.path.join(project_root, 'results_v2.2')
os.makedirs(results_dir, exist_ok=True)

print("ğŸ¯ === T2 v2.2ï¼šå¢å¼ºç‰ˆæœ€ç»ˆæ–¹æ¡ˆ ===\n")

# === æ•°æ®åŠ è½½å’Œé¢„å¤„ç† ===
data_path = os.path.join(project_root, 'data', 'common', 'source', 'dataA.csv')
data = pd.read_csv(data_path, header=None)

columns = ['æ ·æœ¬åºå·', 'å­•å¦‡ä»£ç ', 'å­•å¦‡å¹´é¾„', 'å­•å¦‡èº«é«˜', 'å­•å¦‡ä½“é‡', 'æœ«æ¬¡æœˆç»æ—¶é—´',
           'IVFå¦Šå¨ æ–¹å¼', 'æ£€æµ‹æ—¶é—´', 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°', 'å­•å¦‡æœ¬æ¬¡æ£€æµ‹æ—¶çš„å­•å‘¨', 'å­•å¦‡BMIæŒ‡æ ‡',
           'åŸå§‹æµ‹åºæ•°æ®çš„æ€»è¯»æ®µæ•°', 'æ€»è¯»æ®µæ•°ä¸­åœ¨å‚è€ƒåŸºå› ç»„ä¸Šæ¯”å¯¹çš„æ¯”ä¾‹', 'æ€»è¯»æ®µæ•°ä¸­é‡å¤è¯»æ®µçš„æ¯”ä¾‹',
           'æ€»è¯»æ®µæ•°ä¸­å”¯ä¸€æ¯”å¯¹çš„è¯»æ®µæ•°', 'GCå«é‡', '13å·æŸ“è‰²ä½“çš„Zå€¼', '18å·æŸ“è‰²ä½“çš„Zå€¼',
           '21å·æŸ“è‰²ä½“çš„Zå€¼', 'XæŸ“è‰²ä½“çš„Zå€¼', 'YæŸ“è‰²ä½“çš„Zå€¼', 'YæŸ“è‰²ä½“æµ“åº¦',
           'XæŸ“è‰²ä½“æµ“åº¦', '13å·æŸ“è‰²ä½“çš„GCå«é‡', '18å·æŸ“è‰²ä½“çš„GCå«é‡', '21å·æŸ“è‰²ä½“çš„GCå«é‡',
           'è¢«è¿‡æ»¤æ‰çš„è¯»æ®µæ•°å æ€»è¯»æ®µæ•°çš„æ¯”ä¾‹', 'æ£€æµ‹å‡ºçš„æŸ“è‰²ä½“å¼‚å¸¸', 'å­•å¦‡çš„æ€€å­•æ¬¡æ•°',
           'å­•å¦‡çš„ç”Ÿäº§æ¬¡æ•°', 'èƒå„¿æ˜¯å¦å¥åº·']
data.columns = columns

# é¢„å¤„ç†
male_fetus_data = data[data['YæŸ“è‰²ä½“æµ“åº¦'].notna()].copy()

def safe_float_convert(x):
    try:
        return float(x)
    except:
        return np.nan

numeric_columns = ['å­•å¦‡å¹´é¾„', 'å­•å¦‡èº«é«˜', 'å­•å¦‡ä½“é‡', 'å­•å¦‡BMIæŒ‡æ ‡',
                   'YæŸ“è‰²ä½“æµ“åº¦', 'YæŸ“è‰²ä½“çš„Zå€¼', 'GCå«é‡', 
                   'æ€»è¯»æ®µæ•°ä¸­åœ¨å‚è€ƒåŸºå› ç»„ä¸Šæ¯”å¯¹çš„æ¯”ä¾‹']

for col in numeric_columns:
    male_fetus_data[col] = male_fetus_data[col].apply(safe_float_convert)

def convert_gestational_age(age_str):
    try:
        if isinstance(age_str, str):
            if '+' in age_str:
                weeks, days = age_str.split('w+')
                return float(weeks) + float(days)/7
            elif 'w' in age_str:
                return float(age_str.split('w')[0])
        return float(age_str) if age_str else np.nan
    except:
        return np.nan

male_fetus_data['å­•å‘¨æ•°å€¼'] = male_fetus_data['å­•å¦‡æœ¬æ¬¡æ£€æµ‹æ—¶çš„å­•å‘¨'].apply(convert_gestational_age)
male_fetus_data = male_fetus_data.dropna(subset=['å­•å¦‡BMIæŒ‡æ ‡', 'å­•å‘¨æ•°å€¼', 'YæŸ“è‰²ä½“æµ“åº¦'])

print(f"ğŸ“Š æ•°æ®æ ·æœ¬æ•°: {len(male_fetus_data)}")
print(f"ğŸ“ˆ BMIèŒƒå›´: {male_fetus_data['å­•å¦‡BMIæŒ‡æ ‡'].min():.2f} - {male_fetus_data['å­•å¦‡BMIæŒ‡æ ‡'].max():.2f} kg/mÂ²")

# === 1. å¢å¼ºçš„å¤šç»´é£é™©è¯„ä¼°å‡½æ•° ===

def enhanced_risk_assessment(bmi, age, gestational_week, y_concentration, 
                            gc_content, mapping_ratio, detection_error=0.0):
    """
    å¢å¼ºçš„å¤šç»´é£é™©è¯„ä¼°å‡½æ•°
    
    é£é™©ç»„æˆï¼š
    1. BMIé£é™©ï¼ˆéçº¿æ€§Uå‹æ›²çº¿ï¼‰
    2. å¹´é¾„åˆ†å±‚é£é™©
    3. å­•å‘¨æ—¶ç‚¹é£é™©
    4. YæŸ“è‰²ä½“æµ“åº¦é£é™©
    5. æŠ€æœ¯è´¨é‡é£é™©
    6. æ£€æµ‹è¯¯å·®é£é™©
    """
    
    total_risk = 0.0
    risk_breakdown = {}
    
    # 1. BMIé£é™©ï¼ˆå¢å¼ºçš„éçº¿æ€§æ¨¡å‹ï¼‰
    optimal_bmi = 23.0  # æœ€ä¼˜BMI
    if bmi < 18.5:  # ä½ä½“é‡
        bmi_risk = (18.5 - bmi) ** 1.5 * 0.08
    elif 18.5 <= bmi < 25.0:  # æ­£å¸¸
        bmi_risk = (bmi - optimal_bmi) ** 2 * 0.02
    elif 25.0 <= bmi < 30.0:  # è¶…é‡
        bmi_risk = (bmi - 25.0) ** 1.2 * 0.05
    else:  # è‚¥èƒ–
        bmi_risk = (bmi - 30.0) ** 1.3 * 0.08 + 0.3
    
    risk_breakdown['BMIé£é™©'] = bmi_risk
    total_risk += bmi_risk
    
    # 2. å¹´é¾„åˆ†å±‚é£é™©
    if age < 20:
        age_risk = (20 - age) * 0.03
    elif age > 35:
        age_risk = (age - 35) * 0.025
    else:
        age_risk = 0.0
    
    risk_breakdown['å¹´é¾„é£é™©'] = age_risk
    total_risk += age_risk
    
    # 3. å­•å‘¨æ—¶ç‚¹é£é™©ï¼ˆæœ€ä¼˜çª—å£12-14å‘¨ï¼‰
    optimal_window = [12.0, 14.0]
    if gestational_week < optimal_window[0]:
        week_risk = (optimal_window[0] - gestational_week) ** 1.5 * 0.06
    elif gestational_week > optimal_window[1]:
        week_risk = (gestational_week - optimal_window[1]) ** 1.2 * 0.04
    else:
        week_risk = 0.01  # æœ€ä¼˜çª—å£å†…çš„åŸºç¡€é£é™©
    
    risk_breakdown['æ—¶ç‚¹é£é™©'] = week_risk
    total_risk += week_risk
    
    # 4. YæŸ“è‰²ä½“æµ“åº¦é£é™©
    concentration_p25 = np.percentile(male_fetus_data['YæŸ“è‰²ä½“æµ“åº¦'], 25)
    if y_concentration < concentration_p25:
        conc_risk = (concentration_p25 - y_concentration) / concentration_p25 * 0.8
    else:
        conc_risk = 0.0
    
    risk_breakdown['æµ“åº¦é£é™©'] = conc_risk
    total_risk += conc_risk
    
    # 5. æŠ€æœ¯è´¨é‡é£é™©
    if pd.notna(gc_content) and pd.notna(mapping_ratio):
        # GCå«é‡å¼‚å¸¸é£é™©
        gc_optimal = 0.42  # ç†æƒ³GCå«é‡
        gc_risk = abs(gc_content - gc_optimal) * 0.5
        
        # æ¯”å¯¹è´¨é‡é£é™©
        mapping_risk = max(0, (0.85 - mapping_ratio)) * 2.0  # ä½äº85%æ¯”å¯¹ç‡æœ‰é£é™©
        
        tech_risk = gc_risk + mapping_risk
    else:
        tech_risk = 0.1  # ç¼ºå¤±æ•°æ®çš„é»˜è®¤é£é™©
    
    risk_breakdown['æŠ€æœ¯é£é™©'] = tech_risk
    total_risk += tech_risk
    
    # 6. æ£€æµ‹è¯¯å·®é£é™©
    error_risk = abs(detection_error) * bmi * 0.008
    risk_breakdown['è¯¯å·®é£é™©'] = error_risk
    total_risk += error_risk
    
    return max(0, total_risk), risk_breakdown

# è®¡ç®—å¢å¼ºé£é™©è¯„åˆ†
def calculate_enhanced_risks(data):
    risks = []
    risk_details = []
    
    for _, row in data.iterrows():
        risk, breakdown = enhanced_risk_assessment(
            row['å­•å¦‡BMIæŒ‡æ ‡'], 
            row['å­•å¦‡å¹´é¾„'],
            row['å­•å‘¨æ•°å€¼'], 
            row['YæŸ“è‰²ä½“æµ“åº¦'],
            row.get('GCå«é‡', np.nan),
            row.get('æ€»è¯»æ®µæ•°ä¸­åœ¨å‚è€ƒåŸºå› ç»„ä¸Šæ¯”å¯¹çš„æ¯”ä¾‹', np.nan)
        )
        risks.append(risk)
        risk_details.append(breakdown)
    
    return np.array(risks), risk_details

enhanced_risks, risk_details = calculate_enhanced_risks(male_fetus_data)
male_fetus_data['å¢å¼ºé£é™©è¯„åˆ†'] = enhanced_risks

print(f"ğŸ¯ å¹³å‡é£é™©è¯„åˆ†: {enhanced_risks.mean():.4f}")
print(f"ğŸ“Š é£é™©èŒƒå›´: [{enhanced_risks.min():.4f}, {enhanced_risks.max():.4f}]")

# === 2. éé‡å åˆ†ç»„ç®—æ³• ===

def non_overlapping_grouping(bmi_data, risk_data, n_groups=3, method='risk_gradient'):
    """
    åˆ›å»ºéé‡å çš„BMIåˆ†ç»„
    """
    print(f"\nğŸ”§ æ‰§è¡Œéé‡å åˆ†ç»„ç®—æ³• (n_groups={n_groups})")
    
    if method == 'risk_gradient':
        # åŸºäºé£é™©æ¢¯åº¦çš„åˆ†ç»„
        sorted_indices = np.argsort(bmi_data)
        sorted_bmi = bmi_data[sorted_indices]
        sorted_risk = risk_data[sorted_indices]
        
        # è®¡ç®—é£é™©æ¢¯åº¦
        risk_gradient = np.gradient(sorted_risk)
        
        # å¯»æ‰¾æ¢¯åº¦å˜åŒ–æœ€å¤§çš„ç‚¹ä½œä¸ºåˆ†ç»„è¾¹ç•Œ
        gradient_changes = np.abs(np.gradient(risk_gradient))
        
        # æ‰¾åˆ°å‰n_groups-1ä¸ªæœ€å¤§å˜åŒ–ç‚¹
        boundary_indices = np.argsort(gradient_changes)[-(n_groups-1):]
        boundary_indices = np.sort(boundary_indices)
        
        # è½¬æ¢ä¸ºBMIé˜ˆå€¼
        bmi_thresholds = sorted_bmi[boundary_indices]
        
        print(f"  ğŸ“ é£é™©æ¢¯åº¦åˆ†ç»„é˜ˆå€¼: {bmi_thresholds}")
        
    elif method == 'quantile':
        # åŸºäºç­‰é¢‘åˆ†ç»„
        percentiles = np.linspace(0, 100, n_groups + 1)[1:-1]
        bmi_thresholds = np.percentile(bmi_data, percentiles)
        
        print(f"  ğŸ“ ç­‰é¢‘åˆ†ç»„é˜ˆå€¼: {bmi_thresholds}")
        
    else:  # 'risk_optimized'
        # åŸºäºé£é™©æœ€å°åŒ–çš„åˆ†ç»„
        def objective_function(thresholds):
            if len(thresholds) == 0:
                return np.inf
            
            all_thresholds = np.concatenate([[bmi_data.min()], thresholds, [bmi_data.max()]])
            labels = np.digitize(bmi_data, bins=all_thresholds[1:-1])
            
            total_within_group_variance = 0
            for group_id in np.unique(labels):
                group_mask = labels == group_id
                if np.sum(group_mask) > 1:
                    group_risk = risk_data[group_mask]
                    total_within_group_variance += np.var(group_risk) * np.sum(group_mask)
            
            return total_within_group_variance
        
        # ä½¿ç”¨ç½‘æ ¼æœç´¢ä¼˜åŒ–é˜ˆå€¼
        bmi_range = bmi_data.max() - bmi_data.min()
        best_thresholds = None
        best_score = np.inf
        
        for _ in range(50):  # å¤šæ¬¡éšæœºåˆå§‹åŒ–
            init_thresholds = np.sort(np.random.uniform(
                bmi_data.min() + 0.1 * bmi_range,
                bmi_data.max() - 0.1 * bmi_range,
                n_groups - 1
            ))
            
            score = objective_function(init_thresholds)
            if score < best_score:
                best_score = score
                best_thresholds = init_thresholds
        
        bmi_thresholds = best_thresholds
        print(f"  ğŸ“ é£é™©ä¼˜åŒ–åˆ†ç»„é˜ˆå€¼: {bmi_thresholds}")
    
    # ç”Ÿæˆæ ‡ç­¾
    labels = np.digitize(bmi_data, bins=bmi_thresholds)
    
    # éªŒè¯éé‡å æ€§
    group_ranges = []
    for group_id in sorted(np.unique(labels)):
        group_bmi = bmi_data[labels == group_id]
        group_range = (group_bmi.min(), group_bmi.max())
        group_ranges.append(group_range)
        print(f"  ç»„{group_id}: BMI [{group_range[0]:.2f}, {group_range[1]:.2f}], æ ·æœ¬æ•°: {np.sum(labels == group_id)}")
    
    # æ£€æŸ¥é‡å 
    overlaps = []
    for i in range(len(group_ranges)):
        for j in range(i+1, len(group_ranges)):
            range1, range2 = group_ranges[i], group_ranges[j]
            if not (range1[1] < range2[0] or range2[1] < range1[0]):
                overlap = min(range1[1], range2[1]) - max(range1[0], range2[0])
                overlaps.append((i, j, overlap))
    
    if overlaps:
        print(f"  âš ï¸  æ£€æµ‹åˆ°é‡å : {overlaps}")
    else:
        print(f"  âœ… æˆåŠŸåˆ›å»ºéé‡å åˆ†ç»„")
    
    return labels, bmi_thresholds, group_ranges

# æµ‹è¯•ä¸åŒåˆ†ç»„æ–¹æ³•
grouping_methods = ['risk_gradient', 'quantile', 'risk_optimized']
grouping_results = {}

for method in grouping_methods:
    labels, thresholds, ranges = non_overlapping_grouping(
        male_fetus_data['å­•å¦‡BMIæŒ‡æ ‡'].values,
        male_fetus_data['å¢å¼ºé£é™©è¯„åˆ†'].values,
        n_groups=3,
        method=method
    )
    
    # è®¡ç®—åˆ†ç»„è´¨é‡è¯„åˆ†
    if len(np.unique(labels)) > 1:
        silhouette = silhouette_score(
            male_fetus_data['å­•å¦‡BMIæŒ‡æ ‡'].values.reshape(-1, 1), 
            labels
        )
        
        # è®¡ç®—ç»„å†…é£é™©æ–¹å·®
        within_risk_variance = 0
        for group_id in np.unique(labels):
            group_risks = male_fetus_data['å¢å¼ºé£é™©è¯„åˆ†'].values[labels == group_id]
            if len(group_risks) > 1:
                within_risk_variance += np.var(group_risks)
        
        quality_score = silhouette - 0.1 * within_risk_variance
        
        grouping_results[method] = {
            'labels': labels,
            'thresholds': thresholds,
            'ranges': ranges,
            'silhouette': silhouette,
            'risk_variance': within_risk_variance,
            'quality_score': quality_score
        }
        
        print(f"  ğŸ“Š {method} - è½®å»“ç³»æ•°: {silhouette:.4f}, é£é™©æ–¹å·®: {within_risk_variance:.4f}, è´¨é‡åˆ†: {quality_score:.4f}")

# é€‰æ‹©æœ€ä½³åˆ†ç»„æ–¹æ³•
best_method = max(grouping_results.keys(), key=lambda k: grouping_results[k]['quality_score'])
best_grouping = grouping_results[best_method]
final_labels = best_grouping['labels']
final_ranges = best_grouping['ranges']

print(f"\nğŸ† æœ€ä½³åˆ†ç»„æ–¹æ³•: {best_method}")
print(f"ğŸ“ˆ è´¨é‡è¯„åˆ†: {best_grouping['quality_score']:.4f}")

male_fetus_data['æœ€ç»ˆåˆ†ç»„'] = final_labels

# === 3. ä¸ªæ€§åŒ–NIPTæ—¶ç‚¹é¢„æµ‹ ===

def personalized_timing_optimization(group_data, group_id):
    """
    ä¸ºç‰¹å®šç»„åˆ«ä¼˜åŒ–NIPTæ—¶ç‚¹
    """
    print(f"\nâ° ä¼˜åŒ–ç»„{group_id}çš„NIPTæ—¶ç‚¹")
    
    if len(group_data) == 0:
        return 13.0, 0.0, 0.5
    
    # å®šä¹‰æ—¶ç‚¹å€™é€‰èŒƒå›´
    candidate_weeks = np.arange(10.0, 18.1, 0.5)
    week_scores = []
    
    for week in candidate_weeks:
        # è®¡ç®—è¯¥æ—¶ç‚¹ä¸‹çš„é£é™©è¯„åˆ†
        week_risks = []
        success_indicators = []
        
        for _, row in group_data.iterrows():
            # æ¨¡æ‹Ÿè¯¥æ—¶ç‚¹çš„é£é™©
            risk, _ = enhanced_risk_assessment(
                row['å­•å¦‡BMIæŒ‡æ ‡'], 
                row['å­•å¦‡å¹´é¾„'],
                week,  # ä½¿ç”¨å€™é€‰æ—¶ç‚¹
                row['YæŸ“è‰²ä½“æµ“åº¦'],
                row.get('GCå«é‡', np.nan),
                row.get('æ€»è¯»æ®µæ•°ä¸­åœ¨å‚è€ƒåŸºå› ç»„ä¸Šæ¯”å¯¹çš„æ¯”ä¾‹', np.nan)
            )
            week_risks.append(risk)
            
            # æˆåŠŸç‡æŒ‡æ ‡ï¼ˆYæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡ï¼‰
            concentration_threshold = np.percentile(male_fetus_data['YæŸ“è‰²ä½“æµ“åº¦'], 20)
            success = 1 if row['YæŸ“è‰²ä½“æµ“åº¦'] >= concentration_threshold else 0
            success_indicators.append(success)
        
        avg_risk = np.mean(week_risks)
        success_rate = np.mean(success_indicators)
        
        # ç»¼åˆè¯„åˆ†ï¼šé£é™©è¶Šä½è¶Šå¥½ï¼ŒæˆåŠŸç‡è¶Šé«˜è¶Šå¥½
        composite_score = -avg_risk + 0.3 * success_rate
        week_scores.append(composite_score)
    
    # æ‰¾åˆ°æœ€ä½³æ—¶ç‚¹
    best_week_idx = np.argmax(week_scores)
    optimal_week = candidate_weeks[best_week_idx]
    optimal_score = week_scores[best_week_idx]
    
    # è®¡ç®—è¯¥æ—¶ç‚¹çš„é¢„æœŸæˆåŠŸç‡
    concentration_threshold = np.percentile(male_fetus_data['YæŸ“è‰²ä½“æµ“åº¦'], 20)
    success_rate = np.mean(group_data['YæŸ“è‰²ä½“æµ“åº¦'] >= concentration_threshold)
    
    print(f"  ğŸ¯ æœ€ä¼˜æ—¶ç‚¹: {optimal_week:.1f}å‘¨")
    print(f"  ğŸ“Š ç»¼åˆè¯„åˆ†: {optimal_score:.4f}")
    print(f"  âœ… é¢„æœŸæˆåŠŸç‡: {success_rate:.2%}")
    
    return optimal_week, optimal_score, success_rate

# === 4. é£é™©åˆ†å±‚ä¸ä¸´åºŠå†³ç­–æ”¯æŒ ===

def clinical_risk_stratification(risk_score):
    """
    åŸºäºé£é™©è¯„åˆ†çš„ä¸´åºŠåˆ†å±‚
    """
    if risk_score < 0.5:
        return "æä½é£é™©", "æ ‡å‡†æµç¨‹ï¼Œå¸¸è§„è´¨æ§"
    elif risk_score < 1.0:
        return "ä½é£é™©", "æ ‡å‡†æµç¨‹ï¼ŒåŠ å¼ºè´¨æ§"
    elif risk_score < 2.0:
        return "ä¸­ç­‰é£é™©", "å¢å¼ºç›‘æŠ¤ï¼Œè€ƒè™‘é‡å¤æ£€æµ‹"
    elif risk_score < 3.5:
        return "é«˜é£é™©", "å¯†åˆ‡ç›‘æŠ¤ï¼Œå‡†å¤‡å¤‡é€‰æ–¹æ¡ˆ"
    else:
        return "æé«˜é£é™©", "ç‰¹æ®Šå¤„ç†ï¼Œå¤šå­¦ç§‘ä¼šè¯Š"

def generate_clinical_recommendations(group_data, group_id, optimal_week, success_rate):
    """
    ç”Ÿæˆä¸´åºŠå»ºè®®
    """
    avg_risk = group_data['å¢å¼ºé£é™©è¯„åˆ†'].mean()
    risk_level, base_recommendation = clinical_risk_stratification(avg_risk)
    
    # ä¸ªæ€§åŒ–å»ºè®®
    recommendations = [base_recommendation]
    
    # åŸºäºBMIçš„å»ºè®®
    avg_bmi = group_data['å­•å¦‡BMIæŒ‡æ ‡'].mean()
    if avg_bmi < 18.5:
        recommendations.append("æ³¨æ„è¥å…»è¡¥å……ï¼Œç›‘æ§èƒå„¿å‘è‚²")
    elif avg_bmi > 30:
        recommendations.append("æ§åˆ¶ä½“é‡å¢é•¿ï¼Œç›‘æ§ä»£è°¢æŒ‡æ ‡")
    
    # åŸºäºæˆåŠŸç‡çš„å»ºè®®
    if success_rate < 0.7:
        recommendations.append("å»ºè®®å¤‡é€‰æ£€æµ‹æ–¹æ¡ˆï¼ˆå¦‚ç¾Šæ°´ç©¿åˆºï¼‰")
    elif success_rate > 0.9:
        recommendations.append("é¢„æœŸæ£€æµ‹æ•ˆæœè‰¯å¥½")
    
    # åŸºäºæœ€ä¼˜æ—¶ç‚¹çš„å»ºè®®
    if optimal_week < 12:
        recommendations.append("æ—©æœŸæ£€æµ‹ï¼Œæ³¨æ„cfDNAæµ“åº¦ç›‘æ§")
    elif optimal_week > 15:
        recommendations.append("å»¶è¿Ÿæ£€æµ‹ï¼Œå…³æ³¨èƒå„¿å‘è‚²æƒ…å†µ")
    
    return risk_level, recommendations

# ä¸ºæ¯ç»„ç”Ÿæˆæ¨è
final_recommendations = []

for group_id in sorted(np.unique(final_labels)):
    group_data = male_fetus_data[male_fetus_data['æœ€ç»ˆåˆ†ç»„'] == group_id]
    
    if len(group_data) == 0:
        continue
    
    print(f"\nğŸ“‹ === ç»„{group_id}åˆ†æ ===")
    
    # åŸºæœ¬ä¿¡æ¯
    bmi_range = final_ranges[group_id]
    sample_count = len(group_data)
    avg_risk = group_data['å¢å¼ºé£é™©è¯„åˆ†'].mean()
    
    print(f"ğŸ“Š BMIèŒƒå›´: [{bmi_range[0]:.2f}, {bmi_range[1]:.2f}] kg/mÂ²")
    print(f"ğŸ‘¥ æ ·æœ¬æ•°: {sample_count}")
    print(f"âš¡ å¹³å‡é£é™©: {avg_risk:.4f}")
    
    # æ—¶ç‚¹ä¼˜åŒ–
    optimal_week, optimal_score, success_rate = personalized_timing_optimization(group_data, group_id)
    
    # ä¸´åºŠå»ºè®®
    risk_level, clinical_recommendations = generate_clinical_recommendations(
        group_data, group_id, optimal_week, success_rate
    )
    
    # é£é™©åˆ†è§£åˆ†æ
    avg_risk_breakdown = {}
    
    # é‡æ–°è®¡ç®—è¯¥ç»„çš„é£é™©åˆ†è§£
    group_risks_breakdown = []
    for _, row in group_data.iterrows():
        _, breakdown = enhanced_risk_assessment(
            row['å­•å¦‡BMIæŒ‡æ ‡'], 
            row['å­•å¦‡å¹´é¾„'],
            row['å­•å‘¨æ•°å€¼'], 
            row['YæŸ“è‰²ä½“æµ“åº¦'],
            row.get('GCå«é‡', np.nan),
            row.get('æ€»è¯»æ®µæ•°ä¸­åœ¨å‚è€ƒåŸºå› ç»„ä¸Šæ¯”å¯¹çš„æ¯”ä¾‹', np.nan)
        )
        group_risks_breakdown.append(breakdown)
    
    for component in ['BMIé£é™©', 'å¹´é¾„é£é™©', 'æ—¶ç‚¹é£é™©', 'æµ“åº¦é£é™©', 'æŠ€æœ¯é£é™©', 'è¯¯å·®é£é™©']:
        avg_risk_breakdown[component] = np.mean([detail[component] for detail in group_risks_breakdown])
    
    print(f"ğŸ¥ é£é™©ç­‰çº§: {risk_level}")
    print(f"ğŸ’¡ ä¸´åºŠå»ºè®®: {'; '.join(clinical_recommendations)}")
    print(f"ğŸ”¬ é£é™©åˆ†è§£:")
    for component, value in avg_risk_breakdown.items():
        print(f"   {component}: {value:.4f}")
    
    # ä¿å­˜ç»“æœ
    final_recommendations.append({
        'ç»„åˆ«': f"ç»„{group_id}",
        'BMIä¸‹é™': bmi_range[0],
        'BMIä¸Šé™': bmi_range[1],
        'æ ·æœ¬æ•°': sample_count,
        'æœ€ä¼˜NIPTæ—¶ç‚¹(å‘¨)': optimal_week,
        'é¢„æœŸé£é™©': avg_risk,
        'é¢„æœŸæˆåŠŸç‡(%)': success_rate * 100,
        'é£é™©ç­‰çº§': risk_level,
        'ä¸»è¦å»ºè®®': clinical_recommendations[0],
        'è¯¦ç»†å»ºè®®': '; '.join(clinical_recommendations),
        **{f'{k}': v for k, v in avg_risk_breakdown.items()}
    })

# === 5. æ”¹è¿›çš„éªŒè¯æ¡†æ¶ ===

def enhanced_cross_validation(data, n_folds=5):
    """
    å¢å¼ºçš„äº¤å‰éªŒè¯æ¡†æ¶
    """
    print(f"\nğŸ” æ‰§è¡Œ{n_folds}æŠ˜å¢å¼ºäº¤å‰éªŒè¯")
    
    # åˆ†å±‚é‡‡æ ·ï¼ˆåŸºäºBMIåˆ†ä½æ•°ï¼‰
    bmi_quartiles = pd.qcut(data['å­•å¦‡BMIæŒ‡æ ‡'], q=4, labels=False)
    
    skf = StratifiedKFold(n_splits=n_folds, shuffle=True, random_state=42)
    
    cv_results = {
        'consistency_scores': [],
        'risk_prediction_errors': [],
        'timing_prediction_errors': []
    }
    
    original_labels = data['æœ€ç»ˆåˆ†ç»„'].values
    
    for fold, (train_idx, test_idx) in enumerate(skf.split(data, bmi_quartiles)):
        print(f"  æŠ˜{fold+1}/{n_folds}")
        
        train_data = data.iloc[train_idx]
        test_data = data.iloc[test_idx]
        
        # åœ¨è®­ç»ƒé›†ä¸Šé‡æ–°åˆ†ç»„
        train_labels, _, _ = non_overlapping_grouping(
            train_data['å­•å¦‡BMIæŒ‡æ ‡'].values,
            train_data['å¢å¼ºé£é™©è¯„åˆ†'].values,
            n_groups=3,
            method=best_method
        )
        
        # å°†åˆ†ç»„è§„åˆ™åº”ç”¨åˆ°æµ‹è¯•é›†
        test_bmi = test_data['å­•å¦‡BMIæŒ‡æ ‡'].values
        test_labels = np.digitize(test_bmi, bins=best_grouping['thresholds'])
        
        # è®¡ç®—ä¸€è‡´æ€§
        test_original_labels = original_labels[test_idx]
        consistency = adjusted_rand_score(test_original_labels, test_labels)
        cv_results['consistency_scores'].append(consistency)
        
        # é£é™©é¢„æµ‹è¯¯å·®
        test_risks = test_data['å¢å¼ºé£é™©è¯„åˆ†'].values
        predicted_risks = []
        
        for group_id in np.unique(test_labels):
            group_mask = test_labels == group_id
            if np.sum(group_mask) > 0:
                # ä½¿ç”¨è®­ç»ƒé›†è¯¥ç»„çš„å¹³å‡é£é™©ä½œä¸ºé¢„æµ‹
                train_group_mask = train_labels == group_id
                if np.sum(train_group_mask) > 0:
                    predicted_group_risk = train_data.iloc[train_group_mask]['å¢å¼ºé£é™©è¯„åˆ†'].mean()
                    predicted_risks.extend([predicted_group_risk] * np.sum(group_mask))
                else:
                    predicted_risks.extend([train_data['å¢å¼ºé£é™©è¯„åˆ†'].mean()] * np.sum(group_mask))
        
        risk_mae = np.mean(np.abs(test_risks - predicted_risks))
        cv_results['risk_prediction_errors'].append(risk_mae)
        
        print(f"    ä¸€è‡´æ€§: {consistency:.4f}, é£é™©MAE: {risk_mae:.4f}")
    
    # æ±‡æ€»ç»“æœ
    avg_consistency = np.mean(cv_results['consistency_scores'])
    avg_risk_mae = np.mean(cv_results['risk_prediction_errors'])
    
    print(f"\nğŸ“Š äº¤å‰éªŒè¯ç»“æœ:")
    print(f"  å¹³å‡ä¸€è‡´æ€§(ARI): {avg_consistency:.4f} Â± {np.std(cv_results['consistency_scores']):.4f}")
    print(f"  å¹³å‡é£é™©MAE: {avg_risk_mae:.4f} Â± {np.std(cv_results['risk_prediction_errors']):.4f}")
    
    if avg_consistency > 0.7:
        consistency_level = "é«˜ç¨³å®šæ€§"
    elif avg_consistency > 0.4:
        consistency_level = "ä¸­ç­‰ç¨³å®šæ€§"
    else:
        consistency_level = "ä½ç¨³å®šæ€§"
    
    print(f"  ç¨³å®šæ€§ç­‰çº§: {consistency_level}")
    
    return cv_results, consistency_level

cv_results, consistency_level = enhanced_cross_validation(male_fetus_data)

# === 6. ç»“æœä¿å­˜å’Œå¯è§†åŒ– ===

# ä¿å­˜æ¨èç»“æœ
recommendations_df = pd.DataFrame(final_recommendations)
recommendations_df.to_excel(
    os.path.join(results_dir, 'T2_v2.2_final_recommendations.xlsx'), 
    index=False
)

# ç”Ÿæˆç»¼åˆæŠ¥å‘Š
report_content = f"""
ğŸ¯ === T2 v2.2 å¢å¼ºç‰ˆæœ€ç»ˆåˆ†ææŠ¥å‘Š ===

## ğŸ“Š æ•°æ®æ¦‚å†µ
- æ€»æ ·æœ¬æ•°: {len(male_fetus_data)}
- BMIèŒƒå›´: {male_fetus_data['å­•å¦‡BMIæŒ‡æ ‡'].min():.2f} - {male_fetus_data['å­•å¦‡BMIæŒ‡æ ‡'].max():.2f} kg/mÂ²
- å¹³å‡BMI: {male_fetus_data['å­•å¦‡BMIæŒ‡æ ‡'].mean():.2f} Â± {male_fetus_data['å­•å¦‡BMIæŒ‡æ ‡'].std():.2f} kg/mÂ²

## ğŸ”§ ç®—æ³•æ”¹è¿›æˆæœ
- åˆ†ç»„æ–¹æ³•: {best_method}
- åˆ†ç»„è´¨é‡: {best_grouping['quality_score']:.4f}
- ç¨³å®šæ€§ç­‰çº§: {consistency_level}
- éé‡å åˆ†ç»„: âœ… å·²å®ç°

## ğŸ¥ ä¸´åºŠæ¨èåˆ†ç»„

"""

for _, rec in recommendations_df.iterrows():
    report_content += f"""
### {rec['ç»„åˆ«']}
- BMIèŒƒå›´: [{rec['BMIä¸‹é™']:.2f}, {rec['BMIä¸Šé™']:.2f}] kg/mÂ²
- æ ·æœ¬æ•°: {rec['æ ·æœ¬æ•°']}
- æœ€ä¼˜NIPTæ—¶ç‚¹: {rec['æœ€ä¼˜NIPTæ—¶ç‚¹(å‘¨)']}å‘¨
- é¢„æœŸé£é™©: {rec['é¢„æœŸé£é™©']:.4f}
- é¢„æœŸæˆåŠŸç‡: {rec['é¢„æœŸæˆåŠŸç‡(%)']:.1f}%
- é£é™©ç­‰çº§: {rec['é£é™©ç­‰çº§']}
- ä¸´åºŠå»ºè®®: {rec['è¯¦ç»†å»ºè®®']}

é£é™©åˆ†è§£:
- BMIé£é™©: {rec['BMIé£é™©']:.4f}
- å¹´é¾„é£é™©: {rec['å¹´é¾„é£é™©']:.4f}
- æ—¶ç‚¹é£é™©: {rec['æ—¶ç‚¹é£é™©']:.4f}
- æµ“åº¦é£é™©: {rec['æµ“åº¦é£é™©']:.4f}
- æŠ€æœ¯é£é™©: {rec['æŠ€æœ¯é£é™©']:.4f}
- è¯¯å·®é£é™©: {rec['è¯¯å·®é£é™©']:.4f}
"""

report_content += f"""
## ğŸ” éªŒè¯ç»“æœ
- äº¤å‰éªŒè¯ä¸€è‡´æ€§: {np.mean(cv_results['consistency_scores']):.4f}
- é£é™©é¢„æµ‹è¯¯å·®: {np.mean(cv_results['risk_prediction_errors']):.4f}
- æ¨¡å‹ç¨³å®šæ€§: {consistency_level}

## ğŸ’¡ ä¸»è¦æ”¹è¿›
1. âœ… ä¿®å¤åˆ†ç»„é‡å é—®é¢˜ï¼Œå®ç°çœŸæ­£çš„éé‡å åˆ†ç»„
2. âœ… å¢å¼ºé£é™©å‡½æ•°ï¼ŒåŒ…å«6ä¸ªç»´åº¦çš„é£é™©è¯„ä¼°
3. âœ… ä¸ªæ€§åŒ–NIPTæ—¶ç‚¹é¢„æµ‹ï¼Œä¸å†ç»Ÿä¸€æ¨è
4. âœ… è¯¦ç»†çš„ä¸´åºŠå†³ç­–æ”¯æŒå’Œé£é™©åˆ†å±‚
5. âœ… æ”¹è¿›çš„äº¤å‰éªŒè¯æ¡†æ¶ï¼Œæ›´å‡†ç¡®çš„æ€§èƒ½è¯„ä¼°

## ğŸ¯ ä¸´åºŠåº”ç”¨ä»·å€¼
- æä¾›ç²¾ç¡®çš„BMIåˆ†ç»„æŒ‡å¯¼
- ä¸ªæ€§åŒ–çš„NIPTæ—¶ç‚¹æ¨è
- å…¨é¢çš„é£é™©è¯„ä¼°å’Œåˆ†å±‚ç®¡ç†
- è¯¦ç»†çš„ä¸´åºŠå†³ç­–æ”¯æŒ

---
ç”Ÿæˆæ—¶é—´: {pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')}
ç‰ˆæœ¬: T2 v2.2 å¢å¼ºç‰ˆ
"""

# ä¿å­˜æŠ¥å‘Š
with open(os.path.join(results_dir, 'T2_v2.2_comprehensive_report.txt'), 'w', encoding='utf-8') as f:
    f.write(report_content)

# åˆ›å»ºç»¼åˆå¯è§†åŒ–
plt.figure(figsize=(20, 16))

# 1. éé‡å åˆ†ç»„å¯è§†åŒ–
plt.subplot(3, 4, 1)
colors = ['lightcoral', 'skyblue', 'lightgreen', 'gold', 'lightpink']
for group_id in sorted(np.unique(final_labels)):
    group_data = male_fetus_data[male_fetus_data['æœ€ç»ˆåˆ†ç»„'] == group_id]
    plt.hist(group_data['å­•å¦‡BMIæŒ‡æ ‡'], alpha=0.7, 
             label=f'ç»„{group_id} (n={len(group_data)})', 
             color=colors[group_id % len(colors)], bins=20)

plt.title('éé‡å BMIåˆ†ç»„')
plt.xlabel('BMI (kg/mÂ²)')
plt.ylabel('é¢‘æ•°')
plt.legend()
plt.grid(alpha=0.3)

# 2. é£é™©è¯„åˆ†åˆ†å¸ƒ
plt.subplot(3, 4, 2)
for group_id in sorted(np.unique(final_labels)):
    group_data = male_fetus_data[male_fetus_data['æœ€ç»ˆåˆ†ç»„'] == group_id]
    plt.hist(group_data['å¢å¼ºé£é™©è¯„åˆ†'], alpha=0.6, 
             label=f'ç»„{group_id}', color=colors[group_id % len(colors)], bins=15)

plt.title('å„ç»„é£é™©è¯„åˆ†åˆ†å¸ƒ')
plt.xlabel('å¢å¼ºé£é™©è¯„åˆ†')
plt.ylabel('é¢‘æ•°')
plt.legend()
plt.grid(alpha=0.3)

# 3. ä¸ªæ€§åŒ–æ—¶ç‚¹æ¨è
plt.subplot(3, 4, 3)
group_names = [f"ç»„{i}" for i in sorted(np.unique(final_labels))]
optimal_weeks = [rec['æœ€ä¼˜NIPTæ—¶ç‚¹(å‘¨)'] for rec in final_recommendations]
success_rates = [rec['é¢„æœŸæˆåŠŸç‡(%)'] for rec in final_recommendations]

bars = plt.bar(group_names, optimal_weeks, 
               color=[colors[i % len(colors)] for i in range(len(group_names))], 
               alpha=0.8)

for bar, rate in zip(bars, success_rates):
    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.2,
            f'{rate:.1f}%', ha='center', va='bottom', fontweight='bold')

plt.title('ä¸ªæ€§åŒ–NIPTæ—¶ç‚¹æ¨è')
plt.xlabel('BMIç»„')
plt.ylabel('æœ€ä¼˜å­•å‘¨')
plt.grid(alpha=0.3)

# 4. é£é™©åˆ†è§£é›·è¾¾å›¾
plt.subplot(3, 4, 4)
risk_components = ['BMIé£é™©', 'å¹´é¾„é£é™©', 'æ—¶ç‚¹é£é™©', 'æµ“åº¦é£é™©', 'æŠ€æœ¯é£é™©', 'è¯¯å·®é£é™©']
angles = np.linspace(0, 2*np.pi, len(risk_components), endpoint=False).tolist()
angles += angles[:1]  # é—­åˆ

for i, rec in enumerate(final_recommendations):
    values = [rec[comp] for comp in risk_components]
    values += values[:1]  # é—­åˆ
    
    plt.polar(angles, values, 'o-', label=rec['ç»„åˆ«'], 
              color=colors[i % len(colors)], alpha=0.7)

plt.xticks(angles[:-1], risk_components)
plt.title('é£é™©å› å­åˆ†è§£å¯¹æ¯”')
plt.legend()

# 5. äº¤å‰éªŒè¯ç¨³å®šæ€§
plt.subplot(3, 4, 5)
plt.hist(cv_results['consistency_scores'], bins=10, alpha=0.7, 
         color='lightblue', edgecolor='black')
plt.axvline(np.mean(cv_results['consistency_scores']), color='red', 
            linestyle='--', label=f'å¹³å‡å€¼: {np.mean(cv_results["consistency_scores"]):.3f}')
plt.title('äº¤å‰éªŒè¯ä¸€è‡´æ€§åˆ†å¸ƒ')
plt.xlabel('ARIä¸€è‡´æ€§å¾—åˆ†')
plt.ylabel('é¢‘æ•°')
plt.legend()
plt.grid(alpha=0.3)

# 6. é£é™©vs BMIæ•£ç‚¹å›¾
plt.subplot(3, 4, 6)
for group_id in sorted(np.unique(final_labels)):
    group_data = male_fetus_data[male_fetus_data['æœ€ç»ˆåˆ†ç»„'] == group_id]
    plt.scatter(group_data['å­•å¦‡BMIæŒ‡æ ‡'], group_data['å¢å¼ºé£é™©è¯„åˆ†'], 
               c=colors[group_id % len(colors)], label=f'ç»„{group_id}', alpha=0.6)

plt.title('BMI vs å¢å¼ºé£é™©è¯„åˆ†')
plt.xlabel('BMI (kg/mÂ²)')
plt.ylabel('é£é™©è¯„åˆ†')
plt.legend()
plt.grid(alpha=0.3)

# 7. ç®—æ³•æ€§èƒ½å¯¹æ¯”
plt.subplot(3, 4, 7)
methods = list(grouping_results.keys())
quality_scores = [grouping_results[method]['quality_score'] for method in methods]

bars = plt.bar(methods, quality_scores, alpha=0.8, color='orange')
best_idx = methods.index(best_method)
bars[best_idx].set_color('green')

plt.title('åˆ†ç»„ç®—æ³•æ€§èƒ½å¯¹æ¯”')
plt.xlabel('ç®—æ³•')
plt.ylabel('è´¨é‡è¯„åˆ†')
plt.xticks(rotation=45)
plt.grid(alpha=0.3)

# 8. æˆåŠŸç‡å¯¹æ¯”
plt.subplot(3, 4, 8)
success_rates = [rec['é¢„æœŸæˆåŠŸç‡(%)'] for rec in final_recommendations]
risk_levels = [rec['é£é™©ç­‰çº§'] for rec in final_recommendations]

bars = plt.bar(group_names, success_rates, 
               color=[colors[i % len(colors)] for i in range(len(group_names))], 
               alpha=0.8)

plt.title('å„ç»„é¢„æœŸæˆåŠŸç‡')
plt.xlabel('BMIç»„')
plt.ylabel('æˆåŠŸç‡ (%)')
plt.ylim([0, 100])
plt.grid(alpha=0.3)

# 9. é£é™©ç­‰çº§åˆ†å¸ƒ
plt.subplot(3, 4, 9)
risk_level_counts = {}
for rec in final_recommendations:
    level = rec['é£é™©ç­‰çº§']
    risk_level_counts[level] = risk_level_counts.get(level, 0) + rec['æ ·æœ¬æ•°']

levels = list(risk_level_counts.keys())
counts = list(risk_level_counts.values())

plt.pie(counts, labels=levels, autopct='%1.1f%%', startangle=90)
plt.title('é£é™©ç­‰çº§åˆ†å¸ƒ')

# 10. æ—¶ç‚¹ä¼˜åŒ–æ•ˆæœ
plt.subplot(3, 4, 10)
weeks_range = np.arange(10, 18.1, 0.5)
for i, rec in enumerate(final_recommendations):
    group_data = male_fetus_data[male_fetus_data['æœ€ç»ˆåˆ†ç»„'] == i]
    
    # æ¨¡æ‹Ÿä¸åŒæ—¶ç‚¹çš„é£é™©
    week_risks = []
    for week in weeks_range:
        risks = []
        for _, row in group_data.iterrows():
            risk, _ = enhanced_risk_assessment(
                row['å­•å¦‡BMIæŒ‡æ ‡'], row['å­•å¦‡å¹´é¾„'], week, 
                row['YæŸ“è‰²ä½“æµ“åº¦'], row.get('GCå«é‡', np.nan),
                row.get('æ€»è¯»æ®µæ•°ä¸­åœ¨å‚è€ƒåŸºå› ç»„ä¸Šæ¯”å¯¹çš„æ¯”ä¾‹', np.nan)
            )
            risks.append(risk)
        week_risks.append(np.mean(risks))
    
    plt.plot(weeks_range, week_risks, 'o-', label=f'ç»„{i}', 
             color=colors[i % len(colors)], alpha=0.8)
    
    # æ ‡è®°æœ€ä¼˜ç‚¹
    optimal_week = rec['æœ€ä¼˜NIPTæ—¶ç‚¹(å‘¨)']
    optimal_risk = np.interp(optimal_week, weeks_range, week_risks)
    plt.plot(optimal_week, optimal_risk, 's', markersize=10, 
             color=colors[i % len(colors)], markeredgecolor='black', markeredgewidth=2)

plt.title('NIPTæ—¶ç‚¹ä¼˜åŒ–æ•ˆæœ')
plt.xlabel('å­•å‘¨')
plt.ylabel('å¹³å‡é£é™©')
plt.legend()
plt.grid(alpha=0.3)

# 11. è¯¯å·®æ•æ„Ÿæ€§
plt.subplot(3, 4, 11)
error_levels = [0, 0.02, 0.05, 0.1, 0.15]
error_impacts = []

base_risks = male_fetus_data['å¢å¼ºé£é™©è¯„åˆ†'].values
for error in error_levels:
    error_risks = []
    for _, row in male_fetus_data.iterrows():
        risk, _ = enhanced_risk_assessment(
            row['å­•å¦‡BMIæŒ‡æ ‡'], row['å­•å¦‡å¹´é¾„'], row['å­•å‘¨æ•°å€¼'], 
            row['YæŸ“è‰²ä½“æµ“åº¦'], row.get('GCå«é‡', np.nan),
            row.get('æ€»è¯»æ®µæ•°ä¸­åœ¨å‚è€ƒåŸºå› ç»„ä¸Šæ¯”å¯¹çš„æ¯”ä¾‹', np.nan),
            detection_error=error
        )
        error_risks.append(risk)
    
    impact = (np.mean(error_risks) - np.mean(base_risks)) / np.mean(base_risks) * 100
    error_impacts.append(impact)

plt.plot([e*100 for e in error_levels], error_impacts, 'o-', color='red', linewidth=2)
plt.title('æ£€éªŒè¯¯å·®æ•æ„Ÿæ€§')
plt.xlabel('æ£€éªŒè¯¯å·® (%)')
plt.ylabel('é£é™©å¢å¹… (%)')
plt.grid(alpha=0.3)

# 12. ä¸´åºŠå»ºè®®çŸ©é˜µ
plt.subplot(3, 4, 12)
risk_matrix = np.array([
    [rec['é¢„æœŸé£é™©'] for rec in final_recommendations],
    [rec['é¢„æœŸæˆåŠŸç‡(%)']/100 for rec in final_recommendations],
    [1/(rec['æœ€ä¼˜NIPTæ—¶ç‚¹(å‘¨)']-9) for rec in final_recommendations]  # æ—¶ç‚¹é€‚å®œæ€§
])

im = plt.imshow(risk_matrix, cmap='RdYlGn_r', aspect='auto')
plt.colorbar(im, shrink=0.8)
plt.title('ä¸´åºŠæ¨èçŸ©é˜µ')
plt.xlabel('BMIç»„')
plt.ylabel('è¯„ä¼°ç»´åº¦')
plt.xticks(range(len(group_names)), group_names)
plt.yticks(range(3), ['é¢„æœŸé£é™©', 'æˆåŠŸç‡', 'æ—¶ç‚¹é€‚å®œæ€§'])

# æ·»åŠ æ•°å€¼æ ‡ç­¾
for i in range(risk_matrix.shape[0]):
    for j in range(risk_matrix.shape[1]):
        plt.text(j, i, f'{risk_matrix[i, j]:.3f}', 
                ha='center', va='center', fontweight='bold', fontsize=8)

plt.tight_layout()
plt.savefig(os.path.join(results_dir, 'T2_v2.2_comprehensive_analysis.png'), 
            dpi=500, bbox_inches='tight')
plt.close()

print(report_content)
print(f"\nâœ… T2 v2.2 å¢å¼ºç‰ˆåˆ†æå®Œæˆï¼")
print(f"ğŸ“Š ç»“æœä¿å­˜åœ¨: {results_dir}")
print(f"ğŸ† æœ€ä½³åˆ†ç»„æ–¹æ³•: {best_method}")
print(f"ğŸ“ˆ åˆ†ç»„è´¨é‡è¯„åˆ†: {best_grouping['quality_score']:.4f}")
print(f"ğŸ¯ ç¨³å®šæ€§ç­‰çº§: {consistency_level}")
print(f"ğŸ“‹ æ¨èåˆ†ç»„æ•°: {len(final_recommendations)}")
print(f"âš¡ åˆ†æå›¾è¡¨: T2_v2.2_comprehensive_analysis.png")
