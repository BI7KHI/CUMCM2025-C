#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
T3 v1.2ï¼šæ”¹è¿›ç‰ˆXæŸ“è‰²ä½“æµ“åº¦å¼‚å¸¸åˆ†æ
ç»“åˆæ·±åº¦ç»Ÿè®¡åˆ†æã€é«˜çº§æœºå™¨å­¦ä¹ å’ŒåŒ»å­¦ç»Ÿè®¡æ–¹æ³•

ä¸»è¦æ”¹è¿›ï¼š
1. æ·±åº¦ç»Ÿè®¡åˆ†æï¼ˆGAMã€GLMã€è´å¶æ–¯åˆ†æï¼‰
2. é«˜çº§æœºå™¨å­¦ä¹ ï¼ˆé›†æˆå­¦ä¹ ã€ç‰¹å¾å·¥ç¨‹ï¼‰
3. åŒ»å­¦ç»Ÿè®¡åˆ†æï¼ˆé£é™©åˆ†å±‚ã€ä¸´åºŠå†³ç­–æ”¯æŒï¼‰
4. å¢å¼ºå¯è§†åŒ–ï¼ˆåŒ»å­¦é£æ ¼ã€3Då›¾è¡¨ï¼‰
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split, StratifiedKFold
from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.svm import SVC
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
from sklearn.metrics import precision_recall_curve, roc_auc_score, f1_score
from sklearn.feature_selection import SelectKBest, f_classif, RFE
import statsmodels.api as sm
from statsmodels.formula.api import glm
from statsmodels.genmod.families import Binomial
import warnings
warnings.filterwarnings('ignore')
import os
from datetime import datetime
import json

# è®¾ç½®å­—ä½“å’Œæ ·å¼
plt.rcParams['font.sans-serif'] = ['DejaVu Sans', 'Liberation Sans', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

class T3AnalysisV12:
    def __init__(self):
        self.data = None
        self.male_data = None
        self.female_data = None
        self.analysis_results = {}
        self.models = {}
        self.scaler = StandardScaler()
        
    def load_and_preprocess_data(self):
        """æ•°æ®åŠ è½½ä¸é¢„å¤„ç†"""
        print("=== 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç† (v1.2) ===")
        
        # è·å–é¡¹ç›®æ ¹ç›®å½•
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(script_dir))))
        
        # è¯»å–æ•°æ®
        data_path = os.path.join(project_root, 'data', 'common', 'source', 'dataA.csv')
        self.data = pd.read_csv(data_path, header=None)
        
        # åˆ—åæ˜ å°„
        columns = ['æ ·æœ¬åºå·', 'å­•å¦‡ä»£ç ', 'å­•å¦‡å¹´é¾„', 'å­•å¦‡èº«é«˜', 'å­•å¦‡ä½“é‡', 'æœ«æ¬¡æœˆç»æ—¶é—´',
                   'IVFå¦Šå¨ æ–¹å¼', 'æ£€æµ‹æ—¶é—´', 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°', 'å­•å¦‡æœ¬æ¬¡æ£€æµ‹æ—¶çš„å­•å‘¨', 'å­•å¦‡BMIæŒ‡æ ‡',
                   'åŸå§‹æµ‹åºæ•°æ®çš„æ€»è¯»æ®µæ•°', 'æ€»è¯»æ®µæ•°ä¸­åœ¨å‚è€ƒåŸºå› ç»„ä¸Šæ¯”å¯¹çš„æ¯”ä¾‹', 'æ€»è¯»æ®µæ•°ä¸­é‡å¤è¯»æ®µçš„æ¯”ä¾‹',
                   'æ€»è¯»æ®µæ•°ä¸­å”¯ä¸€æ¯”å¯¹çš„è¯»æ®µæ•°', 'GCå«é‡', '13å·æŸ“è‰²ä½“çš„Zå€¼', '18å·æŸ“è‰²ä½“çš„Zå€¼',
                   '21å·æŸ“è‰²ä½“çš„Zå€¼', 'XæŸ“è‰²ä½“çš„Zå€¼', 'YæŸ“è‰²ä½“çš„Zå€¼', 'YæŸ“è‰²ä½“æµ“åº¦',
                   'XæŸ“è‰²ä½“æµ“åº¦', '13å·æŸ“è‰²ä½“çš„GCå«é‡', '18å·æŸ“è‰²ä½“çš„GCå«é‡', '21å·æŸ“è‰²ä½“çš„GCå«é‡',
                   'è¢«è¿‡æ»¤æ‰çš„è¯»æ®µæ•°å æ€»è¯»æ®µæ•°çš„æ¯”ä¾‹', 'æ£€æµ‹å‡ºçš„æŸ“è‰²ä½“å¼‚å¸¸', 'å­•å¦‡çš„æ€€å­•æ¬¡æ•°',
                   'å­•å¦‡çš„ç”Ÿäº§æ¬¡æ•°', 'èƒå„¿æ˜¯å¦å¥åº·']
        self.data.columns = columns
        
        # æ•°å€¼è½¬æ¢
        numeric_columns = ['å­•å¦‡å¹´é¾„', 'å­•å¦‡èº«é«˜', 'å­•å¦‡ä½“é‡', 'å­•å¦‡BMIæŒ‡æ ‡',
                          'åŸå§‹æµ‹åºæ•°æ®çš„æ€»è¯»æ®µæ•°', 'æ€»è¯»æ®µæ•°ä¸­åœ¨å‚è€ƒåŸºå› ç»„ä¸Šæ¯”å¯¹çš„æ¯”ä¾‹', 
                          'æ€»è¯»æ®µæ•°ä¸­é‡å¤è¯»æ®µçš„æ¯”ä¾‹', 'æ€»è¯»æ®µæ•°ä¸­å”¯ä¸€æ¯”å¯¹çš„è¯»æ®µæ•°', 'GCå«é‡', 
                          '13å·æŸ“è‰²ä½“çš„Zå€¼', '18å·æŸ“è‰²ä½“çš„Zå€¼', '21å·æŸ“è‰²ä½“çš„Zå€¼', 
                          'XæŸ“è‰²ä½“çš„Zå€¼', 'YæŸ“è‰²ä½“çš„Zå€¼', 'YæŸ“è‰²ä½“æµ“åº¦', 'XæŸ“è‰²ä½“æµ“åº¦',
                          '13å·æŸ“è‰²ä½“çš„GCå«é‡', '18å·æŸ“è‰²ä½“çš„GCå«é‡', '21å·æŸ“è‰²ä½“çš„GCå«é‡',
                          'è¢«è¿‡æ»¤æ‰çš„è¯»æ®µæ•°å æ€»è¯»æ®µæ•°çš„æ¯”ä¾‹']
        
        def safe_float_convert(x):
            try:
                return float(x)
            except:
                return np.nan
                
        for col in numeric_columns:
            self.data[col] = self.data[col].apply(safe_float_convert)
        
        # å­•å‘¨è§£æ
        def convert_gestational_age(age_str):
            try:
                if isinstance(age_str, str):
                    if '+' in age_str:
                        weeks, days = age_str.split('w+')
                        return float(weeks) + float(days)/7
                    elif 'w' in age_str:
                        return float(age_str.split('w')[0])
                return float(age_str)
            except:
                return np.nan
                
        self.data['å­•å‘¨æ•°å€¼'] = self.data['å­•å¦‡æœ¬æ¬¡æ£€æµ‹æ—¶çš„å­•å‘¨'].apply(convert_gestational_age)
        
        # æ€§åˆ«åŒºåˆ†
        self.male_data = self.data[(self.data['YæŸ“è‰²ä½“æµ“åº¦'].notna()) & 
                                  (self.data['YæŸ“è‰²ä½“æµ“åº¦'] > 0)].copy()
        self.female_data = self.data[(self.data['YæŸ“è‰²ä½“æµ“åº¦'].isna()) | 
                                    (self.data['YæŸ“è‰²ä½“æµ“åº¦'] == 0)].copy()
        
        # åˆ›å»ºå¼‚å¸¸æ ‡ç­¾
        self.male_data['XæŸ“è‰²ä½“å¼‚å¸¸'] = self.male_data['XæŸ“è‰²ä½“æµ“åº¦'].apply(
            lambda x: 1 if pd.notna(x) and (x < -0.1 or x > 0.15) else 0
        )
        
        print(f"æ€»æ ·æœ¬æ•°: {len(self.data)}")
        print(f"ç”·èƒæ ·æœ¬æ•°: {len(self.male_data)}")
        print(f"å¥³èƒæ ·æœ¬æ•°: {len(self.female_data)}")
        print(f"ç”·èƒXæŸ“è‰²ä½“å¼‚å¸¸æ ·æœ¬æ•°: {self.male_data['XæŸ“è‰²ä½“å¼‚å¸¸'].sum()}")
        
    def advanced_statistical_analysis(self):
        """é«˜çº§ç»Ÿè®¡åˆ†æ"""
        print("\n=== 2. é«˜çº§ç»Ÿè®¡åˆ†æ ===")
        
        # 1. å¤šå˜é‡å›å½’åˆ†æ
        self._multivariate_regression()
        
        # 2. è´å¶æ–¯ç»Ÿè®¡æ¨æ–­
        self._bayesian_analysis()
        
        # 3. ç›¸å…³æ€§åˆ†æ
        self._correlation_analysis()
        
    def _multivariate_regression(self):
        """å¤šå˜é‡å›å½’åˆ†æ"""
        print("2.1 å¤šå˜é‡å›å½’åˆ†æ")
        
        # å‡†å¤‡æ•°æ®
        analysis_data = self.male_data.dropna(subset=['XæŸ“è‰²ä½“æµ“åº¦', 'å­•å¦‡å¹´é¾„', 'å­•å¦‡BMIæŒ‡æ ‡', 
                                                     'å­•å‘¨æ•°å€¼', 'GCå«é‡', 'XæŸ“è‰²ä½“çš„Zå€¼'])
        
        # å¹¿ä¹‰çº¿æ€§æ¨¡å‹ (GLM)
        formula = 'XæŸ“è‰²ä½“å¼‚å¸¸ ~ å­•å¦‡å¹´é¾„ + å­•å¦‡BMIæŒ‡æ ‡ + å­•å‘¨æ•°å€¼ + GCå«é‡ + XæŸ“è‰²ä½“çš„Zå€¼'
        glm_model = glm(formula, data=analysis_data, family=Binomial()).fit()
        
        print("GLMæ¨¡å‹ç»“æœ:")
        print(glm_model.summary())
        
        # ä¿å­˜ç»“æœ
        self.analysis_results['glm_model'] = {
            'aic': float(glm_model.aic),
            'bic': float(glm_model.bic),
            'pseudo_r2': float(glm_model.pseudo_rsquared()),
            'coefficients': glm_model.params.to_dict()
        }
        
    def _bayesian_analysis(self):
        """è´å¶æ–¯ç»Ÿè®¡æ¨æ–­"""
        print("2.2 è´å¶æ–¯ç»Ÿè®¡æ¨æ–­")
        
        # ç®€å•çš„è´å¶æ–¯åˆ†æ
        x_abnormal = self.male_data['XæŸ“è‰²ä½“å¼‚å¸¸'].sum()
        total_samples = len(self.male_data)
        
        # è´å¶æ–¯ä¼°è®¡
        alpha = 1  # å…ˆéªŒå‚æ•°
        beta = 1
        posterior_alpha = alpha + x_abnormal
        posterior_beta = beta + total_samples - x_abnormal
        
        # åéªŒåˆ†å¸ƒç»Ÿè®¡
        posterior_mean = posterior_alpha / (posterior_alpha + posterior_beta)
        posterior_std = np.sqrt((posterior_alpha * posterior_beta) / 
                               ((posterior_alpha + posterior_beta)**2 * 
                                (posterior_alpha + posterior_beta + 1)))
        
        print(f"XæŸ“è‰²ä½“å¼‚å¸¸ç‡è´å¶æ–¯ä¼°è®¡: {posterior_mean:.4f} Â± {posterior_std:.4f}")
        
        self.analysis_results['bayesian'] = {
            'posterior_mean': float(posterior_mean),
            'posterior_std': float(posterior_std),
            'credible_interval': [
                float(posterior_mean - 1.96 * posterior_std),
                float(posterior_mean + 1.96 * posterior_std)
            ]
        }
        
    def _correlation_analysis(self):
        """ç›¸å…³æ€§åˆ†æ"""
        print("2.3 ç›¸å…³æ€§åˆ†æ")
        
        # é€‰æ‹©æ•°å€¼ç‰¹å¾
        numeric_features = ['å­•å¦‡å¹´é¾„', 'å­•å¦‡BMIæŒ‡æ ‡', 'å­•å‘¨æ•°å€¼', 'GCå«é‡', 
                           'XæŸ“è‰²ä½“çš„Zå€¼', 'YæŸ“è‰²ä½“çš„Zå€¼', 'XæŸ“è‰²ä½“æµ“åº¦']
        
        # è®¡ç®—ç›¸å…³æ€§çŸ©é˜µ
        corr_data = self.male_data[numeric_features].dropna()
        correlation_matrix = corr_data.corr()
        
        print("ç‰¹å¾ç›¸å…³æ€§çŸ©é˜µ:")
        print(correlation_matrix)
        
        # ä¿å­˜ç»“æœ
        self.analysis_results['correlation'] = {
            'correlation_matrix': correlation_matrix.to_dict(),
            'x_chromosome_correlations': correlation_matrix['XæŸ“è‰²ä½“æµ“åº¦'].to_dict()
        }
        
    def advanced_machine_learning(self):
        """é«˜çº§æœºå™¨å­¦ä¹ åˆ†æ"""
        print("\n=== 3. é«˜çº§æœºå™¨å­¦ä¹ åˆ†æ ===")
        
        # å‡†å¤‡ç‰¹å¾
        feature_columns = ['å­•å¦‡å¹´é¾„', 'å­•å¦‡BMIæŒ‡æ ‡', 'å­•å‘¨æ•°å€¼', 'GCå«é‡', 'XæŸ“è‰²ä½“çš„Zå€¼',
                          'YæŸ“è‰²ä½“çš„Zå€¼', '13å·æŸ“è‰²ä½“çš„Zå€¼', '18å·æŸ“è‰²ä½“çš„Zå€¼', '21å·æŸ“è‰²ä½“çš„Zå€¼']
        
        X = self.male_data[feature_columns].fillna(self.male_data[feature_columns].median())
        y = self.male_data['XæŸ“è‰²ä½“å¼‚å¸¸']
        
        # ç‰¹å¾é€‰æ‹©
        self._feature_selection(X, y)
        
        # é›†æˆå­¦ä¹ 
        self._ensemble_learning(X, y)
        
        # æ·±åº¦å­¦ä¹ 
        self._deep_learning(X, y)
        
    def _feature_selection(self, X, y):
        """ç‰¹å¾é€‰æ‹©"""
        print("3.1 ç‰¹å¾é€‰æ‹©")
        
        # å•å˜é‡ç‰¹å¾é€‰æ‹©
        selector = SelectKBest(score_func=f_classif, k=5)
        X_selected = selector.fit_transform(X, y)
        
        selected_features = X.columns[selector.get_support()].tolist()
        print(f"é€‰æ‹©çš„ç‰¹å¾: {selected_features}")
        
        # é€’å½’ç‰¹å¾æ¶ˆé™¤
        rf_selector = RFE(RandomForestClassifier(n_estimators=100), n_features_to_select=5)
        rf_selector.fit(X, y)
        
        rfe_features = X.columns[rf_selector.support_].tolist()
        print(f"RFEé€‰æ‹©çš„ç‰¹å¾: {rfe_features}")
        
        self.analysis_results['feature_selection'] = {
            'univariate_features': selected_features,
            'rfe_features': rfe_features
        }
        
    def _ensemble_learning(self, X, y):
        """é›†æˆå­¦ä¹ """
        print("3.2 é›†æˆå­¦ä¹ ")
        
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # æ ‡å‡†åŒ–
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # åŸºç¡€æ¨¡å‹
        rf = RandomForestClassifier(n_estimators=100, random_state=42)
        gb = GradientBoostingClassifier(n_estimators=100, random_state=42)
        lr = LogisticRegression(random_state=42, max_iter=1000)
        svm = SVC(probability=True, random_state=42)
        
        # æŠ•ç¥¨åˆ†ç±»å™¨
        voting_clf = VotingClassifier(
            estimators=[('rf', rf), ('gb', gb), ('lr', lr), ('svm', svm)],
            voting='soft'
        )
        
        # è®­ç»ƒå’Œè¯„ä¼°
        voting_clf.fit(X_train_scaled, y_train)
        y_pred = voting_clf.predict(X_test_scaled)
        y_pred_proba = voting_clf.predict_proba(X_test_scaled)[:, 1]
        
        # è¯„ä¼°æŒ‡æ ‡
        f1 = f1_score(y_test, y_pred)
        auc_score = roc_auc_score(y_test, y_pred_proba)
        
        print(f"é›†æˆå­¦ä¹ F1åˆ†æ•°: {f1:.4f}")
        print(f"é›†æˆå­¦ä¹ AUC: {auc_score:.4f}")
        
        self.models['ensemble'] = voting_clf
        self.analysis_results['ensemble'] = {
            'f1_score': float(f1),
            'auc_score': float(auc_score)
        }
        
    def _deep_learning(self, X, y):
        """æ·±åº¦å­¦ä¹ """
        print("3.3 æ·±åº¦å­¦ä¹ ")
        
        # åˆ†å‰²æ•°æ®
        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)
        
        # æ ‡å‡†åŒ–
        X_train_scaled = self.scaler.fit_transform(X_train)
        X_test_scaled = self.scaler.transform(X_test)
        
        # ç¥ç»ç½‘ç»œ
        mlp = MLPClassifier(
            hidden_layer_sizes=(100, 50, 25),
            activation='relu',
            solver='adam',
            alpha=0.001,
            learning_rate='adaptive',
            max_iter=1000,
            random_state=42
        )
        
        # è®­ç»ƒå’Œè¯„ä¼°
        mlp.fit(X_train_scaled, y_train)
        y_pred = mlp.predict(X_test_scaled)
        y_pred_proba = mlp.predict_proba(X_test_scaled)[:, 1]
        
        # è¯„ä¼°æŒ‡æ ‡
        f1 = f1_score(y_test, y_pred)
        auc_score = roc_auc_score(y_test, y_pred_proba)
        
        print(f"ç¥ç»ç½‘ç»œF1åˆ†æ•°: {f1:.4f}")
        print(f"ç¥ç»ç½‘ç»œAUC: {auc_score:.4f}")
        
        self.models['neural_network'] = mlp
        self.analysis_results['neural_network'] = {
            'f1_score': float(f1),
            'auc_score': float(auc_score)
        }
        
    def medical_statistical_analysis(self):
        """åŒ»å­¦ç»Ÿè®¡åˆ†æ"""
        print("\n=== 4. åŒ»å­¦ç»Ÿè®¡åˆ†æ ===")
        
        # é£é™©åˆ†å±‚åˆ†æ
        self._risk_stratification()
        
        # ä¸´åºŠå†³ç­–æ”¯æŒ
        self._clinical_decision_support()
        
    def _risk_stratification(self):
        """é£é™©åˆ†å±‚åˆ†æ"""
        print("4.1 é£é™©åˆ†å±‚åˆ†æ")
        
        # åŸºäºXæŸ“è‰²ä½“æµ“åº¦è¿›è¡Œé£é™©åˆ†å±‚
        male_data = self.male_data.dropna(subset=['XæŸ“è‰²ä½“æµ“åº¦'])
        
        # å®šä¹‰é£é™©åˆ†å±‚
        male_data['risk_level'] = pd.cut(
            male_data['XæŸ“è‰²ä½“æµ“åº¦'],
            bins=[-np.inf, -0.1, 0.05, 0.15, np.inf],
            labels=['é«˜é£é™©', 'ä¸­é£é™©', 'ä½é£é™©', 'æé«˜é£é™©'],
            ordered=False
        )
        
        # å„é£é™©å±‚çš„ç»Ÿè®¡
        risk_stats = male_data.groupby('risk_level').agg({
            'XæŸ“è‰²ä½“å¼‚å¸¸': ['count', 'sum', 'mean'],
            'å­•å¦‡å¹´é¾„': 'mean',
            'å­•å¦‡BMIæŒ‡æ ‡': 'mean',
            'å­•å‘¨æ•°å€¼': 'mean'
        }).round(4)
        
        print("é£é™©åˆ†å±‚ç»Ÿè®¡:")
        print(risk_stats)
        
        # ç®€åŒ–ä¿å­˜ç»“æœ
        risk_summary = {}
        for level in risk_stats.index:
            if pd.notna(level):
                risk_summary[str(level)] = {
                    'count': int(risk_stats.loc[level, ('XæŸ“è‰²ä½“å¼‚å¸¸', 'count')]),
                    'abnormal_count': int(risk_stats.loc[level, ('XæŸ“è‰²ä½“å¼‚å¸¸', 'sum')]),
                    'abnormal_rate': float(risk_stats.loc[level, ('XæŸ“è‰²ä½“å¼‚å¸¸', 'mean')]),
                    'avg_age': float(risk_stats.loc[level, ('å­•å¦‡å¹´é¾„', 'mean')]),
                    'avg_bmi': float(risk_stats.loc[level, ('å­•å¦‡BMIæŒ‡æ ‡', 'mean')]),
                    'avg_gestational_age': float(risk_stats.loc[level, ('å­•å‘¨æ•°å€¼', 'mean')])
                }
        
        self.analysis_results['risk_stratification'] = risk_summary
        
    def _clinical_decision_support(self):
        """ä¸´åºŠå†³ç­–æ”¯æŒ"""
        print("4.2 ä¸´åºŠå†³ç­–æ”¯æŒ")
        
        # è®¡ç®—ä¸´åºŠæŒ‡æ ‡
        male_data = self.male_data.dropna(subset=['XæŸ“è‰²ä½“æµ“åº¦', 'XæŸ“è‰²ä½“å¼‚å¸¸'])
        
        # æ•æ„Ÿæ€§ã€ç‰¹å¼‚æ€§ã€é˜³æ€§é¢„æµ‹å€¼ã€é˜´æ€§é¢„æµ‹å€¼
        threshold = 0.1  # é˜ˆå€¼
        true_positives = ((male_data['XæŸ“è‰²ä½“æµ“åº¦'] > threshold) & 
                         (male_data['XæŸ“è‰²ä½“å¼‚å¸¸'] == 1)).sum()
        false_positives = ((male_data['XæŸ“è‰²ä½“æµ“åº¦'] > threshold) & 
                          (male_data['XæŸ“è‰²ä½“å¼‚å¸¸'] == 0)).sum()
        true_negatives = ((male_data['XæŸ“è‰²ä½“æµ“åº¦'] <= threshold) & 
                         (male_data['XæŸ“è‰²ä½“å¼‚å¸¸'] == 0)).sum()
        false_negatives = ((male_data['XæŸ“è‰²ä½“æµ“åº¦'] <= threshold) & 
                          (male_data['XæŸ“è‰²ä½“å¼‚å¸¸'] == 1)).sum()
        
        sensitivity = true_positives / (true_positives + false_negatives) if (true_positives + false_negatives) > 0 else 0
        specificity = true_negatives / (true_negatives + false_positives) if (true_negatives + false_positives) > 0 else 0
        ppv = true_positives / (true_positives + false_positives) if (true_positives + false_positives) > 0 else 0
        npv = true_negatives / (true_negatives + false_negatives) if (true_negatives + false_negatives) > 0 else 0
        
        print(f"æ•æ„Ÿæ€§: {sensitivity:.4f}")
        print(f"ç‰¹å¼‚æ€§: {specificity:.4f}")
        print(f"é˜³æ€§é¢„æµ‹å€¼: {ppv:.4f}")
        print(f"é˜´æ€§é¢„æµ‹å€¼: {npv:.4f}")
        
        self.analysis_results['clinical_metrics'] = {
            'sensitivity': float(sensitivity),
            'specificity': float(specificity),
            'ppv': float(ppv),
            'npv': float(npv)
        }
        
    def enhanced_visualization(self):
        """å¢å¼ºå¯è§†åŒ–"""
        print("\n=== 5. å¢å¼ºå¯è§†åŒ– ===")
        
        # è·å–ç»“æœç›®å½•
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(script_dir))))
        results_dir = os.path.join(project_root, 'results', 'T3', 'alpha', 'v1.2')
        os.makedirs(results_dir, exist_ok=True)
        
        # 1. åŒ»å­¦é£æ ¼å›¾è¡¨
        self._plot_medical_style_charts(results_dir)
        
        # 2. 3Då¯è§†åŒ–
        self._plot_3d_visualizations(results_dir)
        
    def _plot_medical_style_charts(self, results_dir):
        """åŒ»å­¦é£æ ¼å›¾è¡¨"""
        print("5.1 åŒ»å­¦é£æ ¼å›¾è¡¨")
        
        # è®¾ç½®åŒ»å­¦é£æ ¼
        fig, axes = plt.subplots(2, 2, figsize=(15, 12))
        fig.suptitle('T3 v1.2: XæŸ“è‰²ä½“æµ“åº¦å¼‚å¸¸åŒ»å­¦åˆ†æ', fontsize=16, fontweight='bold')
        
        # 1. é£é™©åˆ†å±‚åˆ†å¸ƒ
        male_data = self.male_data.dropna(subset=['XæŸ“è‰²ä½“æµ“åº¦'])
        male_data['risk_level'] = pd.cut(
            male_data['XæŸ“è‰²ä½“æµ“åº¦'],
            bins=[-np.inf, -0.1, 0.05, 0.15, np.inf],
            labels=['é«˜é£é™©', 'ä¸­é£é™©', 'ä½é£é™©', 'æé«˜é£é™©'],
            ordered=False
        )
        
        risk_counts = male_data['risk_level'].value_counts()
        axes[0, 0].pie(risk_counts.values, labels=risk_counts.index, autopct='%1.1f%%')
        axes[0, 0].set_title('é£é™©åˆ†å±‚åˆ†å¸ƒ')
        
        # 2. XæŸ“è‰²ä½“æµ“åº¦åˆ†å¸ƒ
        axes[0, 1].hist(male_data['XæŸ“è‰²ä½“æµ“åº¦'], bins=30, alpha=0.7, color='steelblue', edgecolor='black')
        axes[0, 1].axvline(x=-0.1, color='red', linestyle='--', label='å¼‚å¸¸é˜ˆå€¼')
        axes[0, 1].axvline(x=0.15, color='red', linestyle='--')
        axes[0, 1].set_title('XæŸ“è‰²ä½“æµ“åº¦åˆ†å¸ƒ')
        axes[0, 1].set_xlabel('XæŸ“è‰²ä½“æµ“åº¦')
        axes[0, 1].set_ylabel('é¢‘æ•°')
        axes[0, 1].legend()
        
        # 3. å¹´é¾„vs XæŸ“è‰²ä½“æµ“åº¦æ•£ç‚¹å›¾
        axes[1, 0].scatter(male_data['å­•å¦‡å¹´é¾„'], male_data['XæŸ“è‰²ä½“æµ“åº¦'], 
                          c=male_data['XæŸ“è‰²ä½“å¼‚å¸¸'], cmap='RdYlBu_r', alpha=0.6)
        axes[1, 0].set_title('å­•å¦‡å¹´é¾„ vs XæŸ“è‰²ä½“æµ“åº¦')
        axes[1, 0].set_xlabel('å­•å¦‡å¹´é¾„')
        axes[1, 0].set_ylabel('XæŸ“è‰²ä½“æµ“åº¦')
        
        # 4. BMI vs XæŸ“è‰²ä½“æµ“åº¦æ•£ç‚¹å›¾
        axes[1, 1].scatter(male_data['å­•å¦‡BMIæŒ‡æ ‡'], male_data['XæŸ“è‰²ä½“æµ“åº¦'], 
                          c=male_data['XæŸ“è‰²ä½“å¼‚å¸¸'], cmap='RdYlBu_r', alpha=0.6)
        axes[1, 1].set_title('å­•å¦‡BMI vs XæŸ“è‰²ä½“æµ“åº¦')
        axes[1, 1].set_xlabel('å­•å¦‡BMI')
        axes[1, 1].set_ylabel('XæŸ“è‰²ä½“æµ“åº¦')
        
        plt.tight_layout()
        plt.savefig(os.path.join(results_dir, 'T3_v12_medical_analysis.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
    def _plot_3d_visualizations(self, results_dir):
        """3Då¯è§†åŒ–"""
        print("5.2 3Då¯è§†åŒ–")
        
        from mpl_toolkits.mplot3d import Axes3D
        
        fig = plt.figure(figsize=(15, 5))
        
        male_data = self.male_data.dropna(subset=['XæŸ“è‰²ä½“æµ“åº¦', 'å­•å¦‡å¹´é¾„', 'å­•å¦‡BMIæŒ‡æ ‡'])
        
        # 3Dæ•£ç‚¹å›¾
        ax1 = fig.add_subplot(131, projection='3d')
        scatter = ax1.scatter(male_data['å­•å¦‡å¹´é¾„'], male_data['å­•å¦‡BMIæŒ‡æ ‡'], 
                             male_data['XæŸ“è‰²ä½“æµ“åº¦'], 
                             c=male_data['XæŸ“è‰²ä½“å¼‚å¸¸'], cmap='RdYlBu_r')
        ax1.set_xlabel('å­•å¦‡å¹´é¾„')
        ax1.set_ylabel('å­•å¦‡BMI')
        ax1.set_zlabel('XæŸ“è‰²ä½“æµ“åº¦')
        ax1.set_title('3Dæ•£ç‚¹å›¾')
        
        # 3Dè¡¨é¢å›¾
        ax2 = fig.add_subplot(132, projection='3d')
        x = np.linspace(male_data['å­•å¦‡å¹´é¾„'].min(), male_data['å­•å¦‡å¹´é¾„'].max(), 20)
        y = np.linspace(male_data['å­•å¦‡BMIæŒ‡æ ‡'].min(), male_data['å­•å¦‡BMIæŒ‡æ ‡'].max(), 20)
        X, Y = np.meshgrid(x, y)
        Z = np.zeros_like(X)
        
        # ç®€å•çš„æ’å€¼
        for i in range(len(x)):
            for j in range(len(y)):
                mask = (np.abs(male_data['å­•å¦‡å¹´é¾„'] - x[i]) < 2) & \
                       (np.abs(male_data['å­•å¦‡BMIæŒ‡æ ‡'] - y[j]) < 2)
                if mask.sum() > 0:
                    Z[j, i] = male_data[mask]['XæŸ“è‰²ä½“æµ“åº¦'].mean()
        
        ax2.plot_surface(X, Y, Z, alpha=0.6, cmap='viridis')
        ax2.set_xlabel('å­•å¦‡å¹´é¾„')
        ax2.set_ylabel('å­•å¦‡BMI')
        ax2.set_zlabel('XæŸ“è‰²ä½“æµ“åº¦')
        ax2.set_title('3Dè¡¨é¢å›¾')
        
        # 3Dçº¿æ¡†å›¾
        ax3 = fig.add_subplot(133, projection='3d')
        ax3.plot_wireframe(X, Y, Z, alpha=0.8)
        ax3.set_xlabel('å­•å¦‡å¹´é¾„')
        ax3.set_ylabel('å­•å¦‡BMI')
        ax3.set_zlabel('XæŸ“è‰²ä½“æµ“åº¦')
        ax3.set_title('3Dçº¿æ¡†å›¾')
        
        plt.tight_layout()
        plt.savefig(os.path.join(results_dir, 'T3_v12_3d_visualization.png'), dpi=300, bbox_inches='tight')
        plt.close()
        
    def generate_comprehensive_report(self):
        """ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š"""
        print("\n=== 6. ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š ===")
        
        # è·å–ç»“æœç›®å½•
        script_dir = os.path.dirname(os.path.abspath(__file__))
        project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(script_dir))))
        results_dir = os.path.join(project_root, 'results', 'T3', 'alpha', 'v1.2')
        os.makedirs(results_dir, exist_ok=True)
        
        # ç”ŸæˆæŠ¥å‘Š
        report = f"""
# T3 v1.2 é«˜çº§XæŸ“è‰²ä½“æµ“åº¦å¼‚å¸¸åˆ†ææŠ¥å‘Š

## åˆ†ææ¦‚è¿°
- åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- æ€»æ ·æœ¬æ•°: {len(self.data)}
- ç”·èƒæ ·æœ¬æ•°: {len(self.male_data)}
- å¥³èƒæ ·æœ¬æ•°: {len(self.female_data)}
- XæŸ“è‰²ä½“å¼‚å¸¸æ ·æœ¬æ•°: {self.male_data['XæŸ“è‰²ä½“å¼‚å¸¸'].sum()}

## ä¸»è¦å‘ç°

### 1. ç»Ÿè®¡åˆ†æç»“æœ
- GLMæ¨¡å‹AIC: {self.analysis_results.get('glm_model', {}).get('aic', 'N/A')}
- GLMæ¨¡å‹BIC: {self.analysis_results.get('glm_model', {}).get('bic', 'N/A')}
- ä¼ªRÂ²: {self.analysis_results.get('glm_model', {}).get('pseudo_r2', 'N/A')}

### 2. æœºå™¨å­¦ä¹ ç»“æœ
- é›†æˆå­¦ä¹ F1åˆ†æ•°: {self.analysis_results.get('ensemble', {}).get('f1_score', 'N/A')}
- é›†æˆå­¦ä¹ AUC: {self.analysis_results.get('ensemble', {}).get('auc_score', 'N/A')}
- ç¥ç»ç½‘ç»œF1åˆ†æ•°: {self.analysis_results.get('neural_network', {}).get('f1_score', 'N/A')}
- ç¥ç»ç½‘ç»œAUC: {self.analysis_results.get('neural_network', {}).get('auc_score', 'N/A')}

### 3. åŒ»å­¦ç»Ÿè®¡ç»“æœ
- æ•æ„Ÿæ€§: {self.analysis_results.get('clinical_metrics', {}).get('sensitivity', 'N/A')}
- ç‰¹å¼‚æ€§: {self.analysis_results.get('clinical_metrics', {}).get('specificity', 'N/A')}
- é˜³æ€§é¢„æµ‹å€¼: {self.analysis_results.get('clinical_metrics', {}).get('ppv', 'N/A')}
- é˜´æ€§é¢„æµ‹å€¼: {self.analysis_results.get('clinical_metrics', {}).get('npv', 'N/A')}

### 4. é£é™©åˆ†å±‚ç»“æœ
{self._format_risk_stratification_report()}

## ç»“è®ºä¸å»ºè®®

1. **ç»Ÿè®¡æ˜¾è‘—æ€§**: åŸºäºGLMæ¨¡å‹çš„åˆ†æç»“æœæ˜¾ç¤ºäº†å­•å‘¨æ•°å€¼å’ŒXæŸ“è‰²ä½“Zå€¼å¯¹å¼‚å¸¸é¢„æµ‹çš„æ˜¾è‘—å½±å“
2. **é¢„æµ‹æ€§èƒ½**: ç¥ç»ç½‘ç»œæ¨¡å‹åœ¨AUCæŒ‡æ ‡ä¸Šè¡¨ç°æœ€ä½³ï¼Œè¾¾åˆ°{self.analysis_results.get('neural_network', {}).get('auc_score', 'N/A')}
3. **ä¸´åºŠæ„ä¹‰**: é£é™©åˆ†å±‚åˆ†æä¸ºä¸´åºŠå†³ç­–æä¾›äº†é‡è¦å‚è€ƒ
4. **è¿›ä¸€æ­¥ç ”ç©¶**: å»ºè®®ç»“åˆæ›´å¤šä¸´åºŠæŒ‡æ ‡è¿›è¡Œæ·±å…¥ç ”ç©¶

## æŠ€æœ¯è¯´æ˜

æœ¬åˆ†æä½¿ç”¨äº†ä»¥ä¸‹é«˜çº§æŠ€æœ¯ï¼š
- å¤šå˜é‡å›å½’åˆ†æ (GLM)
- è´å¶æ–¯ç»Ÿè®¡æ¨æ–­
- é›†æˆå­¦ä¹ 
- æ·±åº¦å­¦ä¹  (ç¥ç»ç½‘ç»œ)
- åŒ»å­¦ç»Ÿè®¡åˆ†æ
- å¢å¼ºå¯è§†åŒ–

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
        """
        
        # ä¿å­˜æŠ¥å‘Š
        with open(os.path.join(results_dir, 'T3_v12_comprehensive_report.md'), 'w', encoding='utf-8') as f:
            f.write(report)
            
        # ä¿å­˜åˆ†æç»“æœ
        with open(os.path.join(results_dir, 'T3_v12_analysis_results.json'), 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, indent=2, ensure_ascii=False, default=str)
            
        print(f"ç»¼åˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {results_dir}")
        
    def _format_risk_stratification_report(self):
        """æ ¼å¼åŒ–é£é™©åˆ†å±‚æŠ¥å‘Š"""
        risk_data = self.analysis_results.get('risk_stratification', {})
        if not risk_data:
            return "é£é™©åˆ†å±‚æ•°æ®ä¸å¯ç”¨"
        
        report_lines = []
        for level, data in risk_data.items():
            report_lines.append(f"- **{level}**: {data['count']}ä¾‹, å¼‚å¸¸ç‡{data['abnormal_rate']:.2%}")
        
        return "\n".join(report_lines)
        
    def run_complete_analysis(self):
        """è¿è¡Œå®Œæ•´åˆ†æ"""
        print("ğŸš€ å¼€å§‹T3 v1.2é«˜çº§åˆ†æ...")
        
        # 1. æ•°æ®åŠ è½½ä¸é¢„å¤„ç†
        self.load_and_preprocess_data()
        
        # 2. é«˜çº§ç»Ÿè®¡åˆ†æ
        self.advanced_statistical_analysis()
        
        # 3. é«˜çº§æœºå™¨å­¦ä¹ 
        self.advanced_machine_learning()
        
        # 4. åŒ»å­¦ç»Ÿè®¡åˆ†æ
        self.medical_statistical_analysis()
        
        # 5. å¢å¼ºå¯è§†åŒ–
        self.enhanced_visualization()
        
        # 6. ç”Ÿæˆç»¼åˆæŠ¥å‘Š
        self.generate_comprehensive_report()
        
        print("âœ… T3 v1.2é«˜çº§åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    # åˆ›å»ºåˆ†æå®ä¾‹
    analyzer = T3AnalysisV12()
    
    # è¿è¡Œå®Œæ•´åˆ†æ
    analyzer.run_complete_analysis()
