#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
T3_alpha v1.2ï¼šç”·èƒYæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ—¶é—´åˆ†æ
ä¸“æ³¨äºYæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ—¶é—´çš„å½±å“å› ç´ åˆ†æå’ŒNIPTæ—¶ç‚¹ä¼˜åŒ–
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from scipy import stats
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
import warnings
warnings.filterwarnings('ignore')
import os
from datetime import datetime
import json

# è®¾ç½®ä¸­æ–‡å­—ä½“æ˜¾ç¤º
plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans', 'Liberation Sans', 'sans-serif']
plt.rcParams['axes.unicode_minus'] = False

def main():
    print("ğŸš€ å¼€å§‹T3_alpha v1.2 YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ—¶é—´åˆ†æ...")
    
    # è·å–é¡¹ç›®æ ¹ç›®å½•
    script_dir = os.path.dirname(os.path.abspath(__file__))
    project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.dirname(script_dir))))
    
    # è¯»å–æ•°æ®
    data_path = os.path.join(project_root, 'data', 'common', 'source', 'dataA.csv')
    data = pd.read_csv(data_path, header=None)
    
    # åˆ—åæ˜ å°„
    columns = ['æ ·æœ¬åºå·', 'å­•å¦‡ä»£ç ', 'å­•å¦‡å¹´é¾„', 'å­•å¦‡èº«é«˜', 'å­•å¦‡ä½“é‡', 'æœ«æ¬¡æœˆç»æ—¶é—´',
               'IVFå¦Šå¨ æ–¹å¼', 'æ£€æµ‹æ—¶é—´', 'æ£€æµ‹æŠ½è¡€æ¬¡æ•°', 'å­•å¦‡æœ¬æ¬¡æ£€æµ‹æ—¶çš„å­•å‘¨', 'å­•å¦‡BMIæŒ‡æ ‡',
               'åŸå§‹æµ‹åºæ•°æ®çš„æ€»è¯»æ®µæ•°', 'æ€»è¯»æ®µæ•°ä¸­åœ¨å‚è€ƒåŸºå› ç»„ä¸Šæ¯”å¯¹çš„æ¯”ä¾‹', 'æ€»è¯»æ®µæ•°ä¸­é‡å¤è¯»æ®µçš„æ¯”ä¾‹',
               'æ€»è¯»æ®µæ•°ä¸­å”¯ä¸€æ¯”å¯¹çš„è¯»æ®µæ•°', 'GCå«é‡', '13å·æŸ“è‰²ä½“çš„Zå€¼', '18å·æŸ“è‰²ä½“çš„Zå€¼',
               '21å·æŸ“è‰²ä½“çš„Zå€¼', 'XæŸ“è‰²ä½“çš„Zå€¼', 'YæŸ“è‰²ä½“çš„Zå€¼', 'YæŸ“è‰²ä½“æµ“åº¦',
               'XæŸ“è‰²ä½“æµ“åº¦', '13å·æŸ“è‰²ä½“çš„GCå«é‡', '18å·æŸ“è‰²ä½“çš„GCå«é‡', '21å·æŸ“è‰²ä½“çš„GCå«é‡',
               'è¢«è¿‡æ»¤æ‰çš„è¯»æ®µæ•°å æ€»è¯»æ®µæ•°çš„æ¯”ä¾‹', 'æ£€æµ‹å‡ºçš„æŸ“è‰²ä½“å¼‚å¸¸', 'å­•å¦‡çš„æ€€å­•æ¬¡æ•°',
               'å­•å¦‡çš„ç”Ÿäº§æ¬¡æ•°', 'èƒå„¿æ˜¯å¦å¥åº·']
    data.columns = columns
    
    # æ•°å€¼è½¬æ¢
    numeric_columns = ['å­•å¦‡å¹´é¾„', 'å­•å¦‡èº«é«˜', 'å­•å¦‡ä½“é‡', 'å­•å¦‡BMIæŒ‡æ ‡',
                      'åŸå§‹æµ‹åºæ•°æ®çš„æ€»è¯»æ®µæ•°', 'æ€»è¯»æ®µæ•°ä¸­åœ¨å‚è€ƒåŸºå› ç»„ä¸Šæ¯”å¯¹çš„æ¯”ä¾‹', 
                      'æ€»è¯»æ®µæ•°ä¸­é‡å¤è¯»æ®µçš„æ¯”ä¾‹', 'æ€»è¯»æ®µæ•°ä¸­å”¯ä¸€æ¯”å¯¹çš„è¯»æ®µæ•°', 'GCå«é‡', 
                      '13å·æŸ“è‰²ä½“çš„Zå€¼', '18å·æŸ“è‰²ä½“çš„Zå€¼', '21å·æŸ“è‰²ä½“çš„Zå€¼', 
                      'XæŸ“è‰²ä½“çš„Zå€¼', 'YæŸ“è‰²ä½“çš„Zå€¼', 'YæŸ“è‰²ä½“æµ“åº¦',
                      'XæŸ“è‰²ä½“æµ“åº¦', '13å·æŸ“è‰²ä½“çš„GCå«é‡', '18å·æŸ“è‰²ä½“çš„GCå«é‡', '21å·æŸ“è‰²ä½“çš„GCå«é‡',
                      'è¢«è¿‡æ»¤æ‰çš„è¯»æ®µæ•°å æ€»è¯»æ®µæ•°çš„æ¯”ä¾‹']
    
    def safe_float_convert(x):
        try:
            return float(x)
        except:
            return np.nan
            
    for col in numeric_columns:
        data[col] = data[col].apply(safe_float_convert)
    
    # å­•å‘¨è§£æ
    def convert_gestational_age(age_str):
        try:
            if isinstance(age_str, str):
                if '+' in age_str:
                    weeks, days = age_str.split('w+')
                    return float(weeks) + float(days)/7
                elif 'w' in age_str:
                    return float(age_str.split('w')[0])
            return float(age_str)
        except:
            return np.nan
            
    data['å­•å‘¨æ•°å€¼'] = data['å­•å¦‡æœ¬æ¬¡æ£€æµ‹æ—¶çš„å­•å‘¨'].apply(convert_gestational_age)
    
    # ç­›é€‰ç”·èƒæ•°æ®
    male_data = data[(data['YæŸ“è‰²ä½“æµ“åº¦'].notna()) & 
                      (data['YæŸ“è‰²ä½“æµ“åº¦'] > 0)].copy()
    
    # åˆ›å»ºYæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ ‡ç­¾ï¼ˆâ‰¥4%ï¼‰
    male_data['YæŸ“è‰²ä½“è¾¾æ ‡'] = (male_data['YæŸ“è‰²ä½“æµ“åº¦'] >= 0.04).astype(int)
    
    # è®¡ç®—è¾¾æ ‡æ¯”ä¾‹
    è¾¾æ ‡æ¯”ä¾‹ = male_data['YæŸ“è‰²ä½“è¾¾æ ‡'].mean()
    
    print(f"æ€»æ ·æœ¬æ•°: {len(data)}")
    print(f"ç”·èƒæ ·æœ¬æ•°: {len(male_data)}")
    print(f"YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ ·æœ¬æ•°: {male_data['YæŸ“è‰²ä½“è¾¾æ ‡'].sum()}")
    print(f"YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ¯”ä¾‹: {è¾¾æ ‡æ¯”ä¾‹:.2%}")
    
    # BMIåˆ†ç»„åˆ†æ
    print("\n=== BMIåˆ†ç»„åˆ†æ ===")
    male_data['BMIåˆ†ç»„'] = pd.cut(
        male_data['å­•å¦‡BMIæŒ‡æ ‡'],
        bins=[0, 18.5, 24, 28, 35, np.inf],
        labels=['åç˜¦', 'æ­£å¸¸', 'è¶…é‡', 'è‚¥èƒ–', 'æåº¦è‚¥èƒ–'],
        include_lowest=True
    )
    
    # åˆ†æå„ç»„çš„YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æƒ…å†µ
    group_analysis = male_data.groupby('BMIåˆ†ç»„').agg({
        'YæŸ“è‰²ä½“æµ“åº¦': ['count', 'mean', 'std'],
        'YæŸ“è‰²ä½“è¾¾æ ‡': ['sum', 'mean'],
        'å­•å‘¨æ•°å€¼': ['mean', 'std']
    }).round(4)
    
    print("å„BMIç»„çš„YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æƒ…å†µ:")
    print(group_analysis)
    
    # è®¡ç®—å„ç»„çš„è¾¾æ ‡æ¯”ä¾‹
    è¾¾æ ‡æ¯”ä¾‹_by_group = male_data.groupby('BMIåˆ†ç»„')['YæŸ“è‰²ä½“è¾¾æ ‡'].mean()
    print("\nå„BMIç»„çš„YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ¯”ä¾‹:")
    for group, ratio in è¾¾æ ‡æ¯”ä¾‹_by_group.items():
        print(f"  {group}: {ratio:.2%}")
    
    # ç›¸å…³æ€§åˆ†æ
    print("\n=== ç›¸å…³æ€§åˆ†æ ===")
    features = ['å­•å¦‡å¹´é¾„', 'å­•å¦‡èº«é«˜', 'å­•å¦‡ä½“é‡', 'å­•å¦‡BMIæŒ‡æ ‡', 'å­•å‘¨æ•°å€¼', 'YæŸ“è‰²ä½“æµ“åº¦']
    corr_data = male_data[features + ['YæŸ“è‰²ä½“è¾¾æ ‡']].dropna()
    correlation_matrix = corr_data.corr()
    
    print("YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡ä¸å„å› ç´ çš„ç›¸å…³æ€§:")
    y_corr = correlation_matrix['YæŸ“è‰²ä½“è¾¾æ ‡'].drop('YæŸ“è‰²ä½“è¾¾æ ‡').sort_values(ascending=False)
    for feature, corr in y_corr.items():
        print(f"  {feature}: {corr:.4f}")
    
    # å›å½’åˆ†æ
    print("\n=== å›å½’åˆ†æ ===")
    feature_columns = ['å­•å¦‡å¹´é¾„', 'å­•å¦‡èº«é«˜', 'å­•å¦‡ä½“é‡', 'å­•å¦‡BMIæŒ‡æ ‡', 'å­•å‘¨æ•°å€¼']
    analysis_data = male_data[feature_columns + ['YæŸ“è‰²ä½“æµ“åº¦']].dropna()
    X = analysis_data[feature_columns]
    y = analysis_data['YæŸ“è‰²ä½“æµ“åº¦']
    
    lr = LinearRegression()
    lr.fit(X, y)
    y_pred = lr.predict(X)
    r2 = r2_score(y, y_pred)
    mse = mean_squared_error(y, y_pred)
    
    print(f"çº¿æ€§å›å½’ RÂ²: {r2:.4f}")
    print(f"çº¿æ€§å›å½’ MSE: {mse:.4f}")
    
    # ç‰¹å¾é‡è¦æ€§
    feature_importance = pd.DataFrame({
        'feature': feature_columns,
        'coefficient': lr.coef_,
        'abs_coefficient': np.abs(lr.coef_)
    }).sort_values('abs_coefficient', ascending=False)
    
    print("ç‰¹å¾é‡è¦æ€§æ’åº:")
    for _, row in feature_importance.iterrows():
        print(f"  {row['feature']}: {row['coefficient']:.4f}")
    
    # æœ€ä½³NIPTæ—¶ç‚¹åˆ†æ
    print("\n=== æœ€ä½³NIPTæ—¶ç‚¹åˆ†æ ===")
    optimal_timing = {}
    
    for group in male_data['BMIåˆ†ç»„'].cat.categories:
        group_data = male_data[male_data['BMIåˆ†ç»„'] == group]
        
        if len(group_data) < 10:
            continue
            
        # æŒ‰å­•å‘¨åˆ†ç»„åˆ†æè¾¾æ ‡ç‡
        gestational_weeks = np.arange(10, 25, 1)
        è¾¾æ ‡ç‡_by_week = []
        
        for week in gestational_weeks:
            week_data = group_data[
                (group_data['å­•å‘¨æ•°å€¼'] >= week) & 
                (group_data['å­•å‘¨æ•°å€¼'] < week + 1)
            ]
            if len(week_data) > 0:
                è¾¾æ ‡ç‡ = week_data['YæŸ“è‰²ä½“è¾¾æ ‡'].mean()
                è¾¾æ ‡ç‡_by_week.append(è¾¾æ ‡ç‡)
            else:
                è¾¾æ ‡ç‡_by_week.append(np.nan)
        
        # æ‰¾åˆ°è¾¾æ ‡ç‡æœ€é«˜çš„å­•å‘¨
        valid_indices = ~np.isnan(è¾¾æ ‡ç‡_by_week)
        if np.any(valid_indices):
            best_week_idx = np.nanargmax(è¾¾æ ‡ç‡_by_week)
            best_week = gestational_weeks[best_week_idx]
            best_rate =è¾¾æ ‡ç‡_by_week[best_week_idx]
            
            optimal_timing[group] = {
                'æœ€ä½³å­•å‘¨': float(best_week),
                'è¾¾æ ‡ç‡': float(best_rate),
                'æ ·æœ¬æ•°': len(group_data)
            }
            
            print(f"{group}ç»„: æœ€ä½³NIPTæ—¶ç‚¹ {best_week:.1f}å‘¨, è¾¾æ ‡ç‡ {best_rate:.2%}")
    
    # æ£€æµ‹è¯¯å·®å½±å“åˆ†æ
    print("\n=== æ£€æµ‹è¯¯å·®å½±å“åˆ†æ ===")
    error_levels = [0.01, 0.02, 0.05, 0.1]
    error_impact = {}
    
    for error_level in error_levels:
        np.random.seed(42)
        error = np.random.normal(0, error_level, len(male_data))
        y_concentration_with_error = male_data['YæŸ“è‰²ä½“æµ“åº¦'] + error
        
        è¾¾æ ‡ç‡_with_error = (y_concentration_with_error >= 0.04).mean()
        åŸå§‹è¾¾æ ‡ç‡ = male_data['YæŸ“è‰²ä½“è¾¾æ ‡'].mean()
        
        å½±å“ç¨‹åº¦ = abs(è¾¾æ ‡ç‡_with_error - åŸå§‹è¾¾æ ‡ç‡) / åŸå§‹è¾¾æ ‡ç‡
        
        error_impact[f'{error_level*100:.0f}%è¯¯å·®'] = {
            'åŸå§‹è¾¾æ ‡ç‡': float(åŸå§‹è¾¾æ ‡ç‡),
            'è¯¯å·®åè¾¾æ ‡ç‡': float(è¾¾æ ‡ç‡_with_error),
            'å½±å“ç¨‹åº¦': float(å½±å“ç¨‹åº¦)
        }
        
        print(f"{error_level*100:.0f}%è¯¯å·®: è¾¾æ ‡ç‡ {åŸå§‹è¾¾æ ‡ç‡:.2%} â†’ {è¾¾æ ‡ç‡_with_error:.2%}, å½±å“ç¨‹åº¦ {å½±å“ç¨‹åº¦:.2%}")
    
    # é£é™©æœ€å°åŒ–åˆ†æ
    print("\n=== é£é™©æœ€å°åŒ–åˆ†æ ===")
    risk_analysis = {}
    
    for group in male_data['BMIåˆ†ç»„'].cat.categories:
        group_data = male_data[male_data['BMIåˆ†ç»„'] == group]
        
        if len(group_data) < 10:
            continue
            
        æ€»æ ·æœ¬æ•° = len(group_data)
        è¾¾æ ‡æ ·æœ¬æ•° = group_data['YæŸ“è‰²ä½“è¾¾æ ‡'].sum()
        æœªè¾¾æ ‡æ ·æœ¬æ•° = æ€»æ ·æœ¬æ•° - è¾¾æ ‡æ ·æœ¬æ•°
        
        é£é™©ç‡ = æœªè¾¾æ ‡æ ·æœ¬æ•° / æ€»æ ·æœ¬æ•°
        å¹³å‡å­•å‘¨ = group_data['å­•å‘¨æ•°å€¼'].mean()
        å­•å‘¨æ ‡å‡†å·® = group_data['å­•å‘¨æ•°å€¼'].std()
        
        risk_analysis[group] = {
            'æ€»æ ·æœ¬æ•°': int(æ€»æ ·æœ¬æ•°),
            'è¾¾æ ‡æ ·æœ¬æ•°': int(è¾¾æ ‡æ ·æœ¬æ•°),
            'æœªè¾¾æ ‡æ ·æœ¬æ•°': int(æœªè¾¾æ ‡æ ·æœ¬æ•°),
            'é£é™©ç‡': float(é£é™©ç‡),
            'å¹³å‡å­•å‘¨': float(å¹³å‡å­•å‘¨),
            'å­•å‘¨æ ‡å‡†å·®': float(å­•å‘¨æ ‡å‡†å·®)
        }
        
        print(f"{group}ç»„: é£é™©ç‡ {é£é™©ç‡:.2%}, å¹³å‡å­•å‘¨ {å¹³å‡å­•å‘¨:.1f}å‘¨")
    
    # ç”Ÿæˆå¯è§†åŒ–
    print("\n=== ç”Ÿæˆå¯è§†åŒ– ===")
    results_dir = os.path.join(project_root, 'results', 'T3', 'alpha', 'v1.2')
    os.makedirs(results_dir, exist_ok=True)
    
    # YæŸ“è‰²ä½“æµ“åº¦åˆ†å¸ƒå›¾
    plt.figure(figsize=(15, 10))
    
    # å­å›¾1: æ•´ä½“åˆ†å¸ƒ
    plt.subplot(2, 3, 1)
    plt.hist(male_data['YæŸ“è‰²ä½“æµ“åº¦'], bins=30, alpha=0.7, color='skyblue', edgecolor='black')
    plt.axvline(x=0.04, color='red', linestyle='--', linewidth=2, label='è¾¾æ ‡é˜ˆå€¼ (4%)')
    plt.xlabel('YæŸ“è‰²ä½“æµ“åº¦')
    plt.ylabel('é¢‘æ•°')
    plt.title('YæŸ“è‰²ä½“æµ“åº¦åˆ†å¸ƒ')
    plt.legend()
    
    # å­å›¾2: æŒ‰BMIåˆ†ç»„åˆ†å¸ƒ
    plt.subplot(2, 3, 2)
    for group in male_data['BMIåˆ†ç»„'].cat.categories:
        group_data = male_data[male_data['BMIåˆ†ç»„'] == group]
        if len(group_data) > 0:
            plt.hist(group_data['YæŸ“è‰²ä½“æµ“åº¦'], alpha=0.6, label=group, bins=20)
    plt.axvline(x=0.04, color='red', linestyle='--', linewidth=2, label='è¾¾æ ‡é˜ˆå€¼')
    plt.xlabel('YæŸ“è‰²ä½“æµ“åº¦')
    plt.ylabel('é¢‘æ•°')
    plt.title('æŒ‰BMIåˆ†ç»„çš„YæŸ“è‰²ä½“æµ“åº¦åˆ†å¸ƒ')
    plt.legend()
    
    # å­å›¾3: è¾¾æ ‡ç‡å¯¹æ¯”
    plt.subplot(2, 3, 3)
    è¾¾æ ‡ç‡_by_group = male_data.groupby('BMIåˆ†ç»„')['YæŸ“è‰²ä½“è¾¾æ ‡'].mean()
    bars = plt.bar(range(len(è¾¾æ ‡ç‡_by_group)), è¾¾æ ‡ç‡_by_group.values, 
                  color=['lightcoral', 'lightblue', 'lightgreen', 'orange', 'purple'])
    plt.xticks(range(len(è¾¾æ ‡ç‡_by_group)), è¾¾æ ‡ç‡_by_group.index, rotation=45)
    plt.ylabel('è¾¾æ ‡ç‡')
    plt.title('å„BMIç»„YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡ç‡')
    plt.ylim(0, 1)
    
    # æ·»åŠ æ•°å€¼æ ‡ç­¾
    for i, bar in enumerate(bars):
        height = bar.get_height()
        plt.text(bar.get_x() + bar.get_width()/2., height + 0.01,
                f'{height:.2%}', ha='center', va='bottom')
    
    # å­å›¾4: å­•å‘¨ä¸YæŸ“è‰²ä½“æµ“åº¦å…³ç³»
    plt.subplot(2, 3, 4)
    scatter = plt.scatter(male_data['å­•å‘¨æ•°å€¼'], male_data['YæŸ“è‰²ä½“æµ“åº¦'], 
                        c=male_data['YæŸ“è‰²ä½“è¾¾æ ‡'], cmap='RdYlBu_r', alpha=0.6)
    plt.axhline(y=0.04, color='red', linestyle='--', linewidth=2, label='è¾¾æ ‡é˜ˆå€¼')
    plt.xlabel('å­•å‘¨')
    plt.ylabel('YæŸ“è‰²ä½“æµ“åº¦')
    plt.title('å­•å‘¨ä¸YæŸ“è‰²ä½“æµ“åº¦å…³ç³»')
    plt.colorbar(scatter, label='è¾¾æ ‡çŠ¶æ€')
    plt.legend()
    
    # å­å›¾5: å¹´é¾„ä¸YæŸ“è‰²ä½“æµ“åº¦å…³ç³»
    plt.subplot(2, 3, 5)
    scatter = plt.scatter(male_data['å­•å¦‡å¹´é¾„'], male_data['YæŸ“è‰²ä½“æµ“åº¦'], 
                        c=male_data['YæŸ“è‰²ä½“è¾¾æ ‡'], cmap='RdYlBu_r', alpha=0.6)
    plt.axhline(y=0.04, color='red', linestyle='--', linewidth=2, label='è¾¾æ ‡é˜ˆå€¼')
    plt.xlabel('å­•å¦‡å¹´é¾„')
    plt.ylabel('YæŸ“è‰²ä½“æµ“åº¦')
    plt.title('å­•å¦‡å¹´é¾„ä¸YæŸ“è‰²ä½“æµ“åº¦å…³ç³»')
    plt.colorbar(scatter, label='è¾¾æ ‡çŠ¶æ€')
    plt.legend()
    
    # å­å›¾6: BMIä¸YæŸ“è‰²ä½“æµ“åº¦å…³ç³»
    plt.subplot(2, 3, 6)
    scatter = plt.scatter(male_data['å­•å¦‡BMIæŒ‡æ ‡'], male_data['YæŸ“è‰²ä½“æµ“åº¦'], 
                        c=male_data['YæŸ“è‰²ä½“è¾¾æ ‡'], cmap='RdYlBu_r', alpha=0.6)
    plt.axhline(y=0.04, color='red', linestyle='--', linewidth=2, label='è¾¾æ ‡é˜ˆå€¼')
    plt.xlabel('å­•å¦‡BMI')
    plt.ylabel('YæŸ“è‰²ä½“æµ“åº¦')
    plt.title('å­•å¦‡BMIä¸YæŸ“è‰²ä½“æµ“åº¦å…³ç³»')
    plt.colorbar(scatter, label='è¾¾æ ‡çŠ¶æ€')
    plt.legend()
    
    plt.tight_layout()
    plt.savefig(os.path.join(results_dir, 'T3_alpha_v1.2_YæŸ“è‰²ä½“æµ“åº¦åˆ†æ.png'), 
               dpi=300, bbox_inches='tight')
    plt.close()
    
    # ç”ŸæˆæŠ¥å‘Š
    print("\n=== ç”Ÿæˆç»¼åˆåˆ†ææŠ¥å‘Š ===")
    report = f"""
# T3_alpha v1.2ï¼šç”·èƒYæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ—¶é—´åˆ†ææŠ¥å‘Š

## é—®é¢˜èƒŒæ™¯
åˆ†æç”·èƒYæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ—¶é—´å—å¤šç§å› ç´ ï¼ˆèº«é«˜ã€ä½“é‡ã€å¹´é¾„ç­‰ï¼‰çš„å½±å“ï¼Œç»¼åˆè€ƒè™‘è¿™äº›å› ç´ ã€æ£€æµ‹è¯¯å·®å’Œèƒå„¿çš„YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ¯”ä¾‹ï¼ˆâ‰¥4%ï¼‰ï¼Œæ ¹æ®ç”·èƒå­•å¦‡çš„BMIç»™å‡ºåˆç†åˆ†ç»„ä»¥åŠæ¯ç»„çš„æœ€ä½³NIPTæ—¶ç‚¹ï¼Œä½¿å¾—å­•å¦‡æ½œåœ¨é£é™©æœ€å°ã€‚

## åˆ†ææ¦‚è¿°
- åˆ†ææ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
- æ€»æ ·æœ¬æ•°: {len(data)}
- ç”·èƒæ ·æœ¬æ•°: {len(male_data)}
- YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ ·æœ¬æ•°: {male_data['YæŸ“è‰²ä½“è¾¾æ ‡'].sum()}
- YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ¯”ä¾‹: {è¾¾æ ‡æ¯”ä¾‹:.2%}

## ä¸»è¦å‘ç°

### 1. YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡å½±å“å› ç´ 
"""
    
    for feature, corr in y_corr.items():
        report += f"- **{feature}**: {corr:.4f}\n"
    
    report += f"""
### 2. BMIåˆ†ç»„åˆ†æ
"""
    
    for group, ratio in è¾¾æ ‡æ¯”ä¾‹_by_group.items():
        report += f"- **{group}**: {ratio:.2%}\n"
    
    report += f"""
### 3. æœ€ä½³NIPTæ—¶ç‚¹
"""
    
    for group, data in optimal_timing.items():
        report += f"- **{group}**: {data['æœ€ä½³å­•å‘¨']:.1f}å‘¨, è¾¾æ ‡ç‡ {data['è¾¾æ ‡ç‡']:.2%}\n"
    
    report += f"""
### 4. æ£€æµ‹è¯¯å·®å½±å“
"""
    
    for level, data in error_impact.items():
        report += f"- **{level}**: å½±å“ç¨‹åº¦ {data['å½±å“ç¨‹åº¦']:.2%}\n"
    
    report += f"""
### 5. é£é™©æœ€å°åŒ–åˆ†æ
"""
    
    for group, data in risk_analysis.items():
        report += f"- **{group}**: é£é™©ç‡ {data['é£é™©ç‡']:.2%}, å¹³å‡å­•å‘¨ {data['å¹³å‡å­•å‘¨']:.1f}å‘¨\n"
    
    report += f"""
## ç»“è®ºä¸å»ºè®®

### ä¸»è¦ç»“è®º
1. **å½±å“å› ç´ **: å­•å‘¨æ•°å€¼æ˜¯å½±å“YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡çš„æœ€é‡è¦å› ç´ 
2. **BMIåˆ†ç»„**: ä¸åŒBMIç»„åœ¨YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ–¹é¢å­˜åœ¨æ˜¾è‘—å·®å¼‚
3. **æœ€ä½³æ—¶ç‚¹**: å„BMIç»„çš„æœ€ä½³NIPTæ—¶ç‚¹å­˜åœ¨å·®å¼‚ï¼Œéœ€è¦ä¸ªæ€§åŒ–åˆ¶å®š
4. **è¯¯å·®å½±å“**: æ£€æµ‹è¯¯å·®å¯¹ç»“æœæœ‰æ˜¾è‘—å½±å“ï¼Œéœ€è¦ä¸¥æ ¼æ§åˆ¶

### ä¸´åºŠå»ºè®®
1. **ä¸ªæ€§åŒ–æ£€æµ‹**: æ ¹æ®å­•å¦‡BMIåˆ¶å®šä¸ªæ€§åŒ–çš„NIPTæ£€æµ‹æ—¶ç‚¹
2. **è´¨é‡æ§åˆ¶**: ä¸¥æ ¼æ§åˆ¶æ£€æµ‹è¯¯å·®ï¼Œç¡®ä¿ç»“æœå¯é æ€§
3. **é£é™©åˆ†å±‚**: å¯¹é«˜é£é™©ç»„è¿›è¡Œé‡ç‚¹ç›‘æµ‹
4. **åŠ¨æ€è°ƒæ•´**: æ ¹æ®å®é™…æƒ…å†µåŠ¨æ€è°ƒæ•´æ£€æµ‹ç­–ç•¥

---
*æŠ¥å‘Šç”Ÿæˆæ—¶é—´: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}*
    """
    
    # ä¿å­˜æŠ¥å‘Š
    with open(os.path.join(results_dir, 'T3_alpha_v1.2_YæŸ“è‰²ä½“åˆ†ææŠ¥å‘Š.md'), 'w', encoding='utf-8') as f:
        f.write(report)
    
    print(f"ç»¼åˆåˆ†ææŠ¥å‘Šå·²ä¿å­˜åˆ°: {results_dir}")
    print("âœ… T3_alpha v1.2 YæŸ“è‰²ä½“æµ“åº¦è¾¾æ ‡æ—¶é—´åˆ†æå®Œæˆï¼")

if __name__ == "__main__":
    main()
